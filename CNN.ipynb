{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:26.274960Z",
     "start_time": "2024-05-11T13:31:26.271315Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.torch_version\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:26.279437Z",
     "start_time": "2024-05-11T13:31:26.275960Z"
    }
   },
   "id": "a8ff087c4eaccecc",
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "deimention = 50\n",
    "batch_size = 64"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:26.282983Z",
     "start_time": "2024-05-11T13:31:26.280440Z"
    }
   },
   "id": "84fa9c2025989758",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, labels_file, imgs_dir, transform=None):\n",
    "        self.labels = pd.read_csv(labels_file)\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.transform = transform\n",
    "        self.mean_of_color_channels = None  # Initialize as None\n",
    "        self.std_of_color_channels = None   # Initialize as None\n",
    "        self._calculate_stats()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.imgs_dir, self.labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels.iloc[idx, 1]\n",
    "\n",
    "        # Calculate mean and standard deviation if not already done\n",
    "        if self.mean_of_color_channels is None or self.std_of_color_channels is None:\n",
    "            self._calculate_stats()\n",
    "\n",
    "        # Apply transformation with calculated statistics\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _calculate_stats(self):\n",
    "        # Calculate mean and standard deviation across all images in the dataset\n",
    "        # (consider using a random subset for efficiency with large datasets)\n",
    "        channels_sum, channels_squared_sum = np.zeros(3), np.zeros(3)\n",
    "        for idx in range(len(self)):\n",
    "            img_path = os.path.join(self.imgs_dir, self.labels.iloc[idx, 0])\n",
    "            image = np.asarray(Image.open(img_path).convert(\"RGB\"))\n",
    "            # Convert to float for calculations\n",
    "            image = image.astype(np.float32)\n",
    "\n",
    "            # Update channel sums and squared sums\n",
    "            channels_sum += np.sum(image, axis=(0, 1))\n",
    "            channels_squared_sum += np.sum(image**2, axis=(0, 1))\n",
    "\n",
    "        # Calculate mean and standard deviation\n",
    "        num_images = len(self)\n",
    "        self.mean_of_color_channels = channels_sum / (num_images * image.shape[0] * image.shape[1])\n",
    "        self.std_of_color_channels = np.sqrt(channels_squared_sum / (num_images * image.shape[0] * image.shape[1]) - self.mean_of_color_channels**2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:26.291315Z",
     "start_time": "2024-05-11T13:31:26.284125Z"
    }
   },
   "id": "233636c83a3bd26c",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# temp_dataset_for_color_value_extraction = CustomDataset('data/Train/Train.csv', 'data/Train/')\n",
    "# print(temp_dataset_for_color_value_extraction.mean_of_color_channels, temp_dataset_for_color_value_extraction.std_of_color_channels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:26.294835Z",
     "start_time": "2024-05-11T13:31:26.292378Z"
    }
   },
   "id": "3b346482eeb4ced1",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mean_of_color_channels = tuple(item / 255 for item in [131.8612, 121.9361, 116.0298])\n",
    "std_of_color_channels = tuple(item / 255 for item in [88.6042, 87.0262, 87.3879]) # TODO: there might be an issue here\n",
    "\n",
    "\n",
    "train_original_transform = transforms.Compose([ \n",
    "    transforms.Resize((deimention, deimention)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_of_color_channels, std_of_color_channels),\n",
    "])\n",
    "\n",
    "train_transform_modified = transforms.Compose([ \n",
    "    transforms.Resize((deimention, deimention)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_of_color_channels, std_of_color_channels),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((deimention, deimention)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_of_color_channels, std_of_color_channels),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:26.300817Z",
     "start_time": "2024-05-11T13:31:26.295948Z"
    }
   },
   "id": "1ed608ffd0b17b39",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_dataset_original = CustomDataset('data/Train/Train.csv', 'data/Train/', transform=train_original_transform)\n",
    "training_dataset_modified = CustomDataset('data/Train/Train.csv', 'data/Train/', transform=train_transform_modified)\n",
    "validation_dataset = CustomDataset('data/Valid/Validation.csv', 'data/Valid/', transform=test_transform)\n",
    "testing_dataset = CustomDataset('data/Test/Test.csv', 'data/Test/', transform=test_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:35.549910Z",
     "start_time": "2024-05-11T13:31:26.301879Z"
    }
   },
   "id": "c7df6260e09c9b",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_loader_original = DataLoader(training_dataset_original, batch_size=batch_size, shuffle=True)\n",
    "training_loader_modified = DataLoader(training_dataset_modified, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:35.555120Z",
     "start_time": "2024-05-11T13:31:35.550912Z"
    }
   },
   "id": "84a628dbf688a759",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,num_classes,device,dim = 32,num_epochs = 20,learning_rate = 0.001):\n",
    "        super().__init__()\n",
    "        self.num_of_classes = num_classes\n",
    "        self.device = device\n",
    "        self.dim = dim\n",
    "        # Debugging\n",
    "        self.DEBUG = False\n",
    "        # Hyperparameters\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # History while Training\n",
    "        self.model_loss_history = []\n",
    "        self.model_train_acc_history = []\n",
    "        self.model_val_acc_history = []\n",
    "        self.model_val_precision_history = []\n",
    "        self.model_val_recall_history = []\n",
    "        self.model_lr_history = []\n",
    "\n",
    "        # Model Attributes\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = None\n",
    "        self.accuracy = Accuracy(task= 'multiclass', num_classes=self.num_of_classes, average='macro').to(self.device)\n",
    "        self.precision = Precision(task= 'multiclass', num_classes=self.num_of_classes, average='macro').to(self.device)\n",
    "        self.recall = Recall(task= 'multiclass', num_classes=self.num_of_classes, average='macro').to(self.device)\n",
    "        # Model Architecture\n",
    "        self.feature_extract = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(            \n",
    "            nn.Linear(20000, self.num_of_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, img):\n",
    "        '''\n",
    "        returns the predicted classes for the given images\n",
    "        '''\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            img = img.to(self.device)\n",
    "            output = self(img)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            return predicted\n",
    "        \n",
    "\n",
    "    \n",
    "    def eval_val(self, data_loader):\n",
    "        '''\n",
    "        returns accuracy, precision and recall\n",
    "        '''\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                \n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self(images)\n",
    "                self.accuracy(outputs, labels)\n",
    "                self.precision(outputs, labels)\n",
    "                self.recall(outputs, labels)\n",
    "\n",
    "        return self.accuracy.compute(), self.precision.compute(), self.recall.compute()\n",
    "    \n",
    "    def train_model(self, train_loader, val_loader):\n",
    "        \n",
    "        last_accuracy = -100\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i%100 == 0 and self.DEBUG:\n",
    "                    print(\" Step [{}/{}] Loss: {}\".format(i, len(train_loader), loss.item()))\n",
    "                    \n",
    "            val_acc, val_precision, val_recall = self.eval_val(val_loader)\n",
    "            train_acc, _, _ = self.eval_val(train_loader)\n",
    "\n",
    "            self.model_loss_history.append(running_loss/len(train_loader))\n",
    "            self.model_train_acc_history.append(train_acc.item())\n",
    "            self.model_val_acc_history.append(val_acc.item())\n",
    "            self.model_val_precision_history.append(val_precision.item())\n",
    "            self.model_val_recall_history.append(val_recall.item())\n",
    "            self.model_lr_history.append(self.optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "            print(f'Epoch: {epoch+1}/{self.num_epochs}, Loss: {loss.item()},Train Acc: {train_acc}, Val Acc: {val_acc}, Val Precision: {val_precision}, Val Recall: {val_recall}')\n",
    "            \n",
    "            if val_acc > last_accuracy:\n",
    "                last_accuracy = val_acc\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        self.save_model()\n",
    "        print('Finished Training')\n",
    "\n",
    "    def plot_history(self):\n",
    "        # making two plots one for loss and other for accuracy\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle('Model Training History')\n",
    "        axs[0, 0].plot(self.model_loss_history)\n",
    "        axs[0, 0].set_title('Model Loss')\n",
    "        axs[0, 0].set_xlabel('Epochs')\n",
    "        axs[0, 0].set_ylabel('Loss')\n",
    "\n",
    "        axs[0, 1].plot(self.model_train_acc_history, label='Train')\n",
    "        axs[0, 1].plot(self.model_val_acc_history, label='Val')\n",
    "        axs[0, 1].set_title('Model Accuracy')\n",
    "        axs[0, 1].set_xlabel('Epochs')\n",
    "        axs[0, 1].set_ylabel('Accuracy')\n",
    "        axs[0, 1].legend()\n",
    "\n",
    "        axs[1, 0].plot(self.model_val_precision_history)\n",
    "        axs[1, 0].set_title('Model Precision')\n",
    "        axs[1, 0].set_xlabel('Epochs')\n",
    "        axs[1, 0].set_ylabel('Precision')\n",
    "        \n",
    "        axs[1, 1].plot(self.model_val_recall_history)\n",
    "        axs[1, 1].set_title('Model Recall')\n",
    "        axs[1, 1].set_xlabel('Epochs')\n",
    "        axs[1, 1].set_ylabel('Recall')\n",
    "\n",
    "        axs[0, 2].plot(self.model_lr_history)\n",
    "        axs[0, 2].set_title('Learning Rate')\n",
    "        axs[0, 2].set_xlabel('Epochs')\n",
    "        axs[0, 2].set_ylabel('Learning Rate')\n",
    "        \n",
    "        \n",
    "        # axs[1, 2].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.state_dict(),type(self).__name__+'.pth')\n",
    "\n",
    "    def print_summary(self):\n",
    "        summary(self, (3, self.dim, self.dim))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:35.572634Z",
     "start_time": "2024-05-11T13:31:35.556188Z"
    }
   },
   "id": "d59fec1c764305a0",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 50, 50]           2,432\n",
      "         MaxPool2d-2           [-1, 32, 25, 25]               0\n",
      "           Flatten-3                [-1, 20000]               0\n",
      "            Linear-4                    [-1, 2]          40,002\n",
      "================================================================\n",
      "Total params: 42,434\n",
      "Trainable params: 42,434\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 1.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_of_classes = 2\n",
    "model_1 = Model(num_classes=num_of_classes, device=device, dim=deimention, num_epochs=500, learning_rate=0.001)\n",
    "model_1.to(device)\n",
    "model_1.print_summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T13:31:35.594711Z",
     "start_time": "2024-05-11T13:31:35.573640Z"
    }
   },
   "id": "341fcea3ba8288ab",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/500, Loss: 0.2639616131782532,Train Acc: 0.9053245782852173, Val Acc: 0.8902382254600525, Val Precision: 0.8784343004226685, Val Recall: 0.8902382254600525\n",
      "Epoch: 2/500, Loss: 0.09624283760786057,Train Acc: 0.9143646955490112, Val Acc: 0.9017543792724609, Val Precision: 0.8920964002609253, Val Recall: 0.9017543792724609\n",
      "Epoch: 3/500, Loss: 0.11315222829580307,Train Acc: 0.9283357858657837, Val Acc: 0.9131679534912109, Val Precision: 0.9077234268188477, Val Recall: 0.9131679534912109\n",
      "Epoch: 4/500, Loss: 0.21034590899944305,Train Acc: 0.9352672100067139, Val Acc: 0.9256393909454346, Val Precision: 0.9208154678344727, Val Recall: 0.9256393909454346\n",
      "Epoch: 5/500, Loss: 0.06211989000439644,Train Acc: 0.9385992288589478, Val Acc: 0.9326939582824707, Val Precision: 0.9304695129394531, Val Recall: 0.9326939582824707\n",
      "Epoch: 6/500, Loss: 0.030699271708726883,Train Acc: 0.9425690174102783, Val Acc: 0.9365450143814087, Val Precision: 0.9363681674003601, Val Recall: 0.9365450143814087\n",
      "Epoch: 7/500, Loss: 0.04474187269806862,Train Acc: 0.9462331533432007, Val Acc: 0.9410438537597656, Val Precision: 0.9416106939315796, Val Recall: 0.9410438537597656\n",
      "Epoch: 8/500, Loss: 0.009912879206240177,Train Acc: 0.9489336013793945, Val Acc: 0.9443866014480591, Val Precision: 0.9454748034477234, Val Recall: 0.9443866014480591\n",
      "Epoch: 9/500, Loss: 0.01826087012887001,Train Acc: 0.9519585967063904, Val Acc: 0.9475570917129517, Val Precision: 0.9489614367485046, Val Recall: 0.9475570917129517\n",
      "Epoch: 10/500, Loss: 0.048215750604867935,Train Acc: 0.9540180563926697, Val Acc: 0.9507707357406616, Val Precision: 0.952162504196167, Val Recall: 0.9507707357406616\n",
      "Epoch: 11/500, Loss: 0.0617598257958889,Train Acc: 0.9558205604553223, Val Acc: 0.9526106119155884, Val Precision: 0.9539897441864014, Val Recall: 0.9526106119155884\n",
      "Epoch: 12/500, Loss: 0.022726938128471375,Train Acc: 0.9571588039398193, Val Acc: 0.9546187520027161, Val Precision: 0.9560550451278687, Val Recall: 0.9546187520027161\n",
      "Epoch: 13/500, Loss: 0.03189391642808914,Train Acc: 0.9587261080741882, Val Acc: 0.9560215473175049, Val Precision: 0.9576071500778198, Val Recall: 0.9560215473175049\n",
      "Epoch: 14/500, Loss: 0.02797190099954605,Train Acc: 0.9601553678512573, Val Acc: 0.9577422738075256, Val Precision: 0.9592303037643433, Val Recall: 0.9577422738075256\n",
      "Epoch: 15/500, Loss: 0.019137440249323845,Train Acc: 0.9614038467407227, Val Acc: 0.959230899810791, Val Precision: 0.960687518119812, Val Recall: 0.959230899810791\n",
      "Epoch: 16/500, Loss: 0.007904804311692715,Train Acc: 0.9624284505844116, Val Acc: 0.9604524374008179, Val Precision: 0.9618812799453735, Val Recall: 0.9604524374008179\n",
      "Epoch: 17/500, Loss: 0.0035493329633027315,Train Acc: 0.9633325338363647, Val Acc: 0.9615230560302734, Val Precision: 0.9629275798797607, Val Recall: 0.9615230560302734\n",
      "Epoch: 18/500, Loss: 0.006245499476790428,Train Acc: 0.9641362428665161, Val Acc: 0.9624692797660828, Val Precision: 0.9638521671295166, Val Recall: 0.9624692797660828\n",
      "Epoch: 19/500, Loss: 0.012786593288183212,Train Acc: 0.9648552536964417, Val Acc: 0.9633115530014038, Val Precision: 0.9646750688552856, Val Recall: 0.9633115530014038\n",
      "Epoch: 20/500, Loss: 0.00530250882729888,Train Acc: 0.9655566215515137, Val Acc: 0.9641224145889282, Val Precision: 0.9654687643051147, Val Recall: 0.9641224145889282\n",
      "Epoch: 21/500, Loss: 0.0019018681487068534,Train Acc: 0.966139554977417, Val Acc: 0.9647994637489319, Val Precision: 0.9661300182342529, Val Recall: 0.9647994637489319\n",
      "Epoch: 22/500, Loss: 0.002700061770156026,Train Acc: 0.9667000770568848, Val Acc: 0.9654443264007568, Val Precision: 0.966748833656311, Val Recall: 0.9654443264007568\n",
      "Epoch: 23/500, Loss: 0.006631551776081324,Train Acc: 0.9672003984451294, Val Acc: 0.9660192728042603, Val Precision: 0.9673226475715637, Val Recall: 0.9660192728042603\n",
      "Epoch: 24/500, Loss: 0.002923479536548257,Train Acc: 0.9676420092582703, Val Acc: 0.966526985168457, Val Precision: 0.9678183794021606, Val Recall: 0.966526985168457\n",
      "Epoch: 25/500, Loss: 0.004339701496064663,Train Acc: 0.9680482149124146, Val Acc: 0.9669927358627319, Val Precision: 0.9682731628417969, Val Recall: 0.9669927358627319\n",
      "Epoch: 26/500, Loss: 0.007453121244907379,Train Acc: 0.9684232473373413, Val Acc: 0.9674215316772461, Val Precision: 0.9686918258666992, Val Recall: 0.9674215316772461\n",
      "Epoch: 27/500, Loss: 0.004632874857634306,Train Acc: 0.9687705039978027, Val Acc: 0.9678175449371338, Val Precision: 0.969078540802002, Val Recall: 0.9678175449371338\n",
      "Epoch: 28/500, Loss: 0.004352851305156946,Train Acc: 0.9691075086593628, Val Acc: 0.9681994915008545, Val Precision: 0.96946120262146, Val Recall: 0.9681994915008545\n",
      "Epoch: 29/500, Loss: 0.003636119654402137,Train Acc: 0.9694072008132935, Val Acc: 0.9685399532318115, Val Precision: 0.9697931408882141, Val Recall: 0.9685399532318115\n",
      "Epoch: 30/500, Loss: 0.0019029880641028285,Train Acc: 0.9697005748748779, Val Acc: 0.968870997428894, Val Precision: 0.970125138759613, Val Recall: 0.968870997428894\n",
      "Epoch: 31/500, Loss: 0.0013058343902230263,Train Acc: 0.9699749946594238, Val Acc: 0.969180166721344, Val Precision: 0.9704351425170898, Val Recall: 0.969180166721344\n",
      "Epoch: 32/500, Loss: 0.005440739914774895,Train Acc: 0.9702322483062744, Val Acc: 0.9694695472717285, Val Precision: 0.9707252383232117, Val Recall: 0.9694695472717285\n",
      "Epoch: 33/500, Loss: 0.0015085480408743024,Train Acc: 0.9704739451408386, Val Acc: 0.9697408676147461, Val Precision: 0.9709973335266113, Val Recall: 0.9697408676147461\n",
      "Epoch: 34/500, Loss: 0.0018918332643806934,Train Acc: 0.9707014560699463, Val Acc: 0.9699959754943848, Val Precision: 0.9712530374526978, Val Recall: 0.9699959754943848\n",
      "Epoch: 35/500, Loss: 0.0013587863650172949,Train Acc: 0.9709159135818481, Val Acc: 0.97023606300354, Val Precision: 0.9714938402175903, Val Recall: 0.97023606300354\n",
      "Epoch: 36/500, Loss: 0.003802679246291518,Train Acc: 0.9711111187934875, Val Acc: 0.9704550504684448, Val Precision: 0.9717278480529785, Val Recall: 0.9704550504684448\n",
      "Epoch: 37/500, Loss: 0.0015599695034325123,Train Acc: 0.971314013004303, Val Acc: 0.9706804752349854, Val Precision: 0.9719606637954712, Val Recall: 0.9706804752349854\n",
      "Epoch: 38/500, Loss: 0.00495555205270648,Train Acc: 0.9714953899383545, Val Acc: 0.9708828926086426, Val Precision: 0.9721629619598389, Val Recall: 0.9708828926086426\n",
      "Epoch: 39/500, Loss: 0.001189009752124548,Train Acc: 0.9716675281524658, Val Acc: 0.9710745811462402, Val Precision: 0.9723546504974365, Val Recall: 0.9710745811462402\n",
      "Epoch: 40/500, Loss: 0.0015113706467673182,Train Acc: 0.9718310832977295, Val Acc: 0.9712566137313843, Val Precision: 0.9725366830825806, Val Recall: 0.9712566137313843\n",
      "Epoch: 41/500, Loss: 0.0010981801897287369,Train Acc: 0.9719865918159485, Val Acc: 0.9714294672012329, Val Precision: 0.9727095365524292, Val Recall: 0.9714294672012329\n",
      "Epoch: 42/500, Loss: 0.0021210089325904846,Train Acc: 0.9721347093582153, Val Acc: 0.971593976020813, Val Precision: 0.9728740453720093, Val Recall: 0.971593976020813\n",
      "Epoch: 43/500, Loss: 0.0012060232693329453,Train Acc: 0.972275972366333, Val Acc: 0.9717507362365723, Val Precision: 0.9730308055877686, Val Recall: 0.9717507362365723\n",
      "Epoch: 44/500, Loss: 0.0010898393811658025,Train Acc: 0.9724200963973999, Val Acc: 0.971909761428833, Val Precision: 0.9731956720352173, Val Recall: 0.971909761428833\n",
      "Epoch: 45/500, Loss: 0.0005291455308906734,Train Acc: 0.9725487232208252, Val Acc: 0.9720522165298462, Val Precision: 0.9733380079269409, Val Recall: 0.9720522165298462\n",
      "Epoch: 46/500, Loss: 0.00141821033321321,Train Acc: 0.9726717472076416, Val Acc: 0.9721883535385132, Val Precision: 0.9734740257263184, Val Recall: 0.9721883535385132\n",
      "Epoch: 47/500, Loss: 0.001292666420340538,Train Acc: 0.9727895259857178, Val Acc: 0.9723186492919922, Val Precision: 0.9736042022705078, Val Recall: 0.9723186492919922\n",
      "Epoch: 48/500, Loss: 0.0012673281598836184,Train Acc: 0.9729024171829224, Val Acc: 0.9724434614181519, Val Precision: 0.9737288951873779, Val Recall: 0.9724434614181519\n",
      "Epoch: 49/500, Loss: 0.0008036408689804375,Train Acc: 0.9730107188224792, Val Acc: 0.9725630283355713, Val Precision: 0.9738483428955078, Val Recall: 0.9725630283355713\n",
      "Epoch: 50/500, Loss: 0.0009932469110935926,Train Acc: 0.9731146693229675, Val Acc: 0.9726777672767639, Val Precision: 0.9739629626274109, Val Recall: 0.9726777672767639\n",
      "Epoch: 51/500, Loss: 0.001372808706946671,Train Acc: 0.9732145071029663, Val Acc: 0.9727879166603088, Val Precision: 0.9740729928016663, Val Recall: 0.9727879166603088\n",
      "Epoch: 52/500, Loss: 0.0009579308680258691,Train Acc: 0.9733105301856995, Val Acc: 0.9728938341140747, Val Precision: 0.9741787314414978, Val Recall: 0.9728938341140747\n",
      "Epoch: 53/500, Loss: 0.0016133165918290615,Train Acc: 0.9733952283859253, Val Acc: 0.9729877710342407, Val Precision: 0.9742676615715027, Val Recall: 0.9729877710342407\n",
      "Epoch: 54/500, Loss: 0.0013469948899000883,Train Acc: 0.973476767539978, Val Acc: 0.973078191280365, Val Precision: 0.9743531942367554, Val Recall: 0.973078191280365\n",
      "Epoch: 55/500, Loss: 0.00028669179300777614,Train Acc: 0.9735627770423889, Val Acc: 0.9731727838516235, Val Precision: 0.9744479656219482, Val Recall: 0.9731727838516235\n",
      "Epoch: 56/500, Loss: 0.0007134893094189465,Train Acc: 0.9736384153366089, Val Acc: 0.9732565879821777, Val Precision: 0.97452712059021, Val Recall: 0.9732565879821777\n",
      "Epoch: 57/500, Loss: 0.0007793002878315747,Train Acc: 0.973718523979187, Val Acc: 0.9733446836471558, Val Precision: 0.9746154546737671, Val Recall: 0.9733446836471558\n",
      "Epoch: 58/500, Loss: 0.0009051068918779492,Train Acc: 0.9737889170646667, Val Acc: 0.9734225869178772, Val Precision: 0.9746888875961304, Val Recall: 0.9734225869178772\n",
      "Epoch: 59/500, Loss: 0.0006030871300026774,Train Acc: 0.9738568663597107, Val Acc: 0.973497748374939, Val Precision: 0.9747598767280579, Val Recall: 0.973497748374939\n",
      "Epoch: 60/500, Loss: 0.0006079982849769294,Train Acc: 0.9739225506782532, Val Acc: 0.9735704064369202, Val Precision: 0.9748284816741943, Val Recall: 0.9735704064369202\n",
      "Epoch: 61/500, Loss: 0.000422434153733775,Train Acc: 0.9739860892295837, Val Acc: 0.9736406207084656, Val Precision: 0.9748947620391846, Val Recall: 0.9736406207084656\n",
      "Epoch: 62/500, Loss: 0.0007986362907104194,Train Acc: 0.9740475416183472, Val Acc: 0.9737085103988647, Val Precision: 0.9749588966369629, Val Recall: 0.9737085103988647\n",
      "Epoch: 63/500, Loss: 0.0006833748193457723,Train Acc: 0.9741177558898926, Val Acc: 0.9737851619720459, Val Precision: 0.9750276803970337, Val Recall: 0.9737851619720459\n",
      "Epoch: 64/500, Loss: 0.0003017377166543156,Train Acc: 0.9741753339767456, Val Acc: 0.9738486409187317, Val Precision: 0.9750876426696777, Val Recall: 0.9738486409187317\n",
      "Epoch: 65/500, Loss: 0.0004114887269679457,Train Acc: 0.9742310047149658, Val Acc: 0.9739101529121399, Val Precision: 0.9751458168029785, Val Recall: 0.9739101529121399\n",
      "Epoch: 66/500, Loss: 0.00040314410580322146,Train Acc: 0.9743014574050903, Val Acc: 0.9739863872528076, Val Precision: 0.9752187728881836, Val Recall: 0.9739863872528076\n",
      "Epoch: 67/500, Loss: 0.0003986986994277686,Train Acc: 0.9743637442588806, Val Acc: 0.9740541577339172, Val Precision: 0.9752795100212097, Val Recall: 0.9740541577339172\n",
      "Epoch: 68/500, Loss: 0.0004946383996866643,Train Acc: 0.9744241237640381, Val Acc: 0.9741199016571045, Val Precision: 0.9753383994102478, Val Recall: 0.9741199016571045\n",
      "Epoch: 69/500, Loss: 0.0003310480678919703,Train Acc: 0.9744828343391418, Val Acc: 0.9741837382316589, Val Precision: 0.9753956198692322, Val Recall: 0.9741837382316589\n",
      "Epoch: 70/500, Loss: 0.0004681547870859504,Train Acc: 0.9745302200317383, Val Acc: 0.9742359519004822, Val Precision: 0.975445032119751, Val Recall: 0.9742359519004822\n",
      "Epoch: 71/500, Loss: 0.0007906058453954756,Train Acc: 0.9745762348175049, Val Acc: 0.974286675453186, Val Precision: 0.9754931330680847, Val Recall: 0.974286675453186\n",
      "Epoch: 72/500, Loss: 0.0007425849908031523,Train Acc: 0.9746303558349609, Val Acc: 0.9743454456329346, Val Precision: 0.9755457639694214, Val Recall: 0.9743454456329346\n",
      "Epoch: 73/500, Loss: 0.0007275662501342595,Train Acc: 0.9746737480163574, Val Acc: 0.9743932485580444, Val Precision: 0.9755910634994507, Val Recall: 0.9743932485580444\n",
      "Epoch: 74/500, Loss: 0.0002984056482091546,Train Acc: 0.974725067615509, Val Acc: 0.9744490385055542, Val Precision: 0.9756408929824829, Val Recall: 0.9744490385055542\n",
      "Epoch: 75/500, Loss: 0.000604639237280935,Train Acc: 0.9747750163078308, Val Acc: 0.974503219127655, Val Precision: 0.9756893515586853, Val Recall: 0.974503219127655\n",
      "Epoch: 76/500, Loss: 0.0003124428039882332,Train Acc: 0.9748236536979675, Val Acc: 0.9745559692382812, Val Precision: 0.9757364988327026, Val Recall: 0.9745559692382812\n",
      "Epoch: 77/500, Loss: 0.0005803859094157815,Train Acc: 0.974871039390564, Val Acc: 0.9746074080467224, Val Precision: 0.9757825136184692, Val Recall: 0.9746074080467224\n",
      "Epoch: 78/500, Loss: 0.00011253251432208344,Train Acc: 0.9749171733856201, Val Acc: 0.974657416343689, Val Precision: 0.9758272171020508, Val Recall: 0.974657416343689\n",
      "Epoch: 79/500, Loss: 0.00021878023108001798,Train Acc: 0.9749622344970703, Val Acc: 0.97470623254776, Val Precision: 0.9758708477020264, Val Recall: 0.97470623254776\n",
      "Epoch: 80/500, Loss: 0.0002572479424998164,Train Acc: 0.975006103515625, Val Acc: 0.9747537970542908, Val Precision: 0.9759133458137512, Val Recall: 0.9747537970542908\n",
      "Epoch: 81/500, Loss: 6.36162149021402e-05,Train Acc: 0.9750488996505737, Val Acc: 0.9748001098632812, Val Precision: 0.9759547710418701, Val Recall: 0.9748001098632812\n",
      "Epoch: 82/500, Loss: 0.00031216585193760693,Train Acc: 0.9750906229019165, Val Acc: 0.9748453497886658, Val Precision: 0.9759951829910278, Val Recall: 0.9748453497886658\n",
      "Epoch: 83/500, Loss: 0.0002950505295302719,Train Acc: 0.9751313328742981, Val Acc: 0.9748895168304443, Val Precision: 0.9760346412658691, Val Recall: 0.9748895168304443\n",
      "Epoch: 84/500, Loss: 0.0003490782983135432,Train Acc: 0.975179135799408, Val Acc: 0.9749406576156616, Val Precision: 0.9760782122612, Val Recall: 0.9749406576156616\n",
      "Epoch: 85/500, Loss: 0.00029778695898130536,Train Acc: 0.975217878818512, Val Acc: 0.9749825596809387, Val Precision: 0.9761157035827637, Val Recall: 0.9749825596809387\n",
      "Epoch: 86/500, Loss: 0.00040647428249940276,Train Acc: 0.9752557277679443, Val Acc: 0.9750235080718994, Val Precision: 0.9761523008346558, Val Recall: 0.9750235080718994\n",
      "Epoch: 87/500, Loss: 0.0004415423609316349,Train Acc: 0.9753004312515259, Val Acc: 0.975071370601654, Val Precision: 0.9761929512023926, Val Recall: 0.975071370601654\n",
      "Epoch: 88/500, Loss: 0.00023339217295870185,Train Acc: 0.975336492061615, Val Acc: 0.9751104116439819, Val Precision: 0.976227879524231, Val Recall: 0.9751104116439819\n",
      "Epoch: 89/500, Loss: 0.0001586967846378684,Train Acc: 0.9753792881965637, Val Acc: 0.9751560688018799, Val Precision: 0.9762667417526245, Val Recall: 0.9751560688018799\n",
      "Epoch: 90/500, Loss: 0.0004533562168944627,Train Acc: 0.9754136800765991, Val Acc: 0.9751932621002197, Val Precision: 0.9763001203536987, Val Recall: 0.9751932621002197\n",
      "Epoch: 91/500, Loss: 0.00028727296739816666,Train Acc: 0.9754546880722046, Val Acc: 0.9752371311187744, Val Precision: 0.9763373136520386, Val Recall: 0.9752371311187744\n",
      "Epoch: 92/500, Loss: 0.0003324505523778498,Train Acc: 0.9754948019981384, Val Acc: 0.9752799272537231, Val Precision: 0.9763736724853516, Val Recall: 0.9752799272537231\n",
      "Epoch: 93/500, Loss: 0.0003768489696085453,Train Acc: 0.9755340814590454, Val Acc: 0.975321888923645, Val Precision: 0.9764092564582825, Val Recall: 0.975321888923645\n",
      "Epoch: 94/500, Loss: 0.00013334312825463712,Train Acc: 0.9755724668502808, Val Acc: 0.9753628969192505, Val Precision: 0.9764441251754761, Val Recall: 0.9753628969192505\n",
      "Epoch: 95/500, Loss: 0.00012062972382409498,Train Acc: 0.975610077381134, Val Acc: 0.9754030704498291, Val Precision: 0.9764782190322876, Val Recall: 0.9754030704498291\n",
      "Epoch: 96/500, Loss: 0.00027673295699059963,Train Acc: 0.9756469130516052, Val Acc: 0.9754424095153809, Val Precision: 0.9765115976333618, Val Recall: 0.9754424095153809\n",
      "Epoch: 97/500, Loss: 0.00024796390789560974,Train Acc: 0.9756829738616943, Val Acc: 0.9754809141159058, Val Precision: 0.9765442609786987, Val Recall: 0.9754809141159058\n",
      "Epoch: 98/500, Loss: 6.597297760890797e-05,Train Acc: 0.9757183194160461, Val Acc: 0.9755185842514038, Val Precision: 0.9765762686729431, Val Recall: 0.9755185842514038\n",
      "Epoch: 99/500, Loss: 0.00026801458443515003,Train Acc: 0.9757529497146606, Val Acc: 0.9755555391311646, Val Precision: 0.976607620716095, Val Recall: 0.9755555391311646\n",
      "Epoch: 100/500, Loss: 0.00026782520581036806,Train Acc: 0.9757868647575378, Val Acc: 0.9755917191505432, Val Precision: 0.9766383171081543, Val Recall: 0.9755917191505432\n",
      "Epoch: 101/500, Loss: 0.00022649593302048743,Train Acc: 0.9758201241493225, Val Acc: 0.9756271839141846, Val Precision: 0.9766684770584106, Val Recall: 0.9756271839141846\n",
      "Epoch: 102/500, Loss: 0.00023604130547028035,Train Acc: 0.9758527278900146, Val Acc: 0.9756619930267334, Val Precision: 0.9766979813575745, Val Recall: 0.9756619930267334\n",
      "Epoch: 103/500, Loss: 0.00018816438387148082,Train Acc: 0.9758846759796143, Val Acc: 0.9756960868835449, Val Precision: 0.9767268896102905, Val Recall: 0.9756960868835449\n",
      "Epoch: 104/500, Loss: 0.0002875027130357921,Train Acc: 0.9759160280227661, Val Acc: 0.9757294654846191, Val Precision: 0.9767552614212036, Val Recall: 0.9757294654846191\n",
      "Epoch: 105/500, Loss: 0.0001158207596745342,Train Acc: 0.9759467840194702, Val Acc: 0.9757622480392456, Val Precision: 0.9767831563949585, Val Recall: 0.9757622480392456\n",
      "Epoch: 106/500, Loss: 0.00020625708566512913,Train Acc: 0.9759770035743713, Val Acc: 0.9757944345474243, Val Precision: 0.9768104553222656, Val Recall: 0.9757944345474243\n",
      "Epoch: 107/500, Loss: 0.00017711156397126615,Train Acc: 0.9760066270828247, Val Acc: 0.9758259654045105, Val Precision: 0.9768372178077698, Val Recall: 0.9758259654045105\n",
      "Epoch: 108/500, Loss: 0.00023506823345087469,Train Acc: 0.9760357141494751, Val Acc: 0.9758569598197937, Val Precision: 0.9768635034561157, Val Recall: 0.9758569598197937\n",
      "Epoch: 109/500, Loss: 0.00014801185170654207,Train Acc: 0.9760642051696777, Val Acc: 0.9758873581886292, Val Precision: 0.9768892526626587, Val Recall: 0.9758873581886292\n",
      "Epoch: 110/500, Loss: 0.00021409307373687625,Train Acc: 0.9760922193527222, Val Acc: 0.9759172201156616, Val Precision: 0.976914644241333, Val Recall: 0.9759172201156616\n",
      "Epoch: 111/500, Loss: 0.0002218042645836249,Train Acc: 0.9761197566986084, Val Acc: 0.9759464859962463, Val Precision: 0.9769394993782043, Val Recall: 0.9759464859962463\n",
      "Epoch: 112/500, Loss: 0.0001476882171118632,Train Acc: 0.9761467576026917, Val Acc: 0.9759752750396729, Val Precision: 0.9769639372825623, Val Recall: 0.9759752750396729\n",
      "Epoch: 113/500, Loss: 0.000135612950543873,Train Acc: 0.9761732816696167, Val Acc: 0.9760035276412964, Val Precision: 0.976987898349762, Val Recall: 0.9760035276412964\n",
      "Epoch: 114/500, Loss: 0.00010835144348675385,Train Acc: 0.9761993885040283, Val Acc: 0.9760313034057617, Val Precision: 0.9770114421844482, Val Recall: 0.9760313034057617\n",
      "Epoch: 115/500, Loss: 8.470260218018666e-05,Train Acc: 0.9762250185012817, Val Acc: 0.9760586023330688, Val Precision: 0.9770346283912659, Val Recall: 0.9760586023330688\n",
      "Epoch: 116/500, Loss: 0.00025439210003241897,Train Acc: 0.976250171661377, Val Acc: 0.976085364818573, Val Precision: 0.9770573377609253, Val Recall: 0.976085364818573\n",
      "Epoch: 117/500, Loss: 7.298577838810161e-05,Train Acc: 0.9762749671936035, Val Acc: 0.9761117100715637, Val Precision: 0.9770797491073608, Val Recall: 0.9761117100715637\n",
      "Epoch: 118/500, Loss: 0.00016023163334466517,Train Acc: 0.9762992858886719, Val Acc: 0.9761375784873962, Val Precision: 0.9771016836166382, Val Recall: 0.9761375784873962\n",
      "Epoch: 119/500, Loss: 0.00020418060012161732,Train Acc: 0.976323127746582, Val Acc: 0.9761630296707153, Val Precision: 0.9771233201026917, Val Recall: 0.9761630296707153\n",
      "Epoch: 120/500, Loss: 9.650998254073784e-05,Train Acc: 0.9763467311859131, Val Acc: 0.976188063621521, Val Precision: 0.9771445393562317, Val Recall: 0.976188063621521\n",
      "Epoch: 121/500, Loss: 0.00010399513121228665,Train Acc: 0.9763698577880859, Val Acc: 0.9762126207351685, Val Precision: 0.9771654605865479, Val Recall: 0.9762126207351685\n",
      "Epoch: 122/500, Loss: 0.00010480089258635417,Train Acc: 0.9763926267623901, Val Acc: 0.976236879825592, Val Precision: 0.9771859645843506, Val Recall: 0.976236879825592\n",
      "Epoch: 123/500, Loss: 0.00026589081971906126,Train Acc: 0.9764149785041809, Val Acc: 0.9762606620788574, Val Precision: 0.9772061705589294, Val Recall: 0.9762606620788574\n",
      "Epoch: 124/500, Loss: 0.00011931896005989984,Train Acc: 0.976436972618103, Val Acc: 0.9762840867042542, Val Precision: 0.9772260785102844, Val Recall: 0.9762840867042542\n",
      "Epoch: 125/500, Loss: 0.00023672301904298365,Train Acc: 0.9764586687088013, Val Acc: 0.9763071537017822, Val Precision: 0.9772456288337708, Val Recall: 0.9763071537017822\n",
      "Epoch: 126/500, Loss: 0.00010592561739031225,Train Acc: 0.9764800071716309, Val Acc: 0.9763298034667969, Val Precision: 0.9772648811340332, Val Recall: 0.9763298034667969\n",
      "Epoch: 127/500, Loss: 6.930564268259332e-05,Train Acc: 0.9765009880065918, Val Acc: 0.9763520956039429, Val Precision: 0.9772838354110718, Val Recall: 0.9763520956039429\n",
      "Epoch: 128/500, Loss: 0.0001050874125212431,Train Acc: 0.9765216112136841, Val Acc: 0.9763740301132202, Val Precision: 0.9773024320602417, Val Recall: 0.9763740301132202\n",
      "Epoch: 129/500, Loss: 8.660839375806972e-05,Train Acc: 0.9765419960021973, Val Acc: 0.9763957262039185, Val Precision: 0.9773207902908325, Val Recall: 0.9763957262039185\n",
      "Epoch: 130/500, Loss: 5.285690713208169e-05,Train Acc: 0.9765620231628418, Val Acc: 0.9764170050621033, Val Precision: 0.9773389101028442, Val Recall: 0.9764170050621033\n",
      "Epoch: 131/500, Loss: 0.0001392591802868992,Train Acc: 0.9765817523002625, Val Acc: 0.9764379262924194, Val Precision: 0.9773566722869873, Val Recall: 0.9764379262924194\n",
      "Epoch: 132/500, Loss: 8.910894393920898e-05,Train Acc: 0.9766011834144592, Val Acc: 0.9764585494995117, Val Precision: 0.9773741960525513, Val Recall: 0.9764585494995117\n",
      "Epoch: 133/500, Loss: 0.00011514124344103038,Train Acc: 0.9766203165054321, Val Acc: 0.9764789342880249, Val Precision: 0.9773914813995361, Val Recall: 0.9764789342880249\n",
      "Epoch: 134/500, Loss: 0.00010220278636552393,Train Acc: 0.9766391515731812, Val Acc: 0.9764989614486694, Val Precision: 0.9774084091186523, Val Recall: 0.9764989614486694\n",
      "Epoch: 135/500, Loss: 0.00012089018855476752,Train Acc: 0.9766577482223511, Val Acc: 0.9765186309814453, Val Precision: 0.977425217628479, Val Recall: 0.9765186309814453\n",
      "Epoch: 136/500, Loss: 0.00012713771138805896,Train Acc: 0.9766759872436523, Val Acc: 0.9765380620956421, Val Precision: 0.977441668510437, Val Recall: 0.9765380620956421\n",
      "Epoch: 137/500, Loss: 4.107555287191644e-05,Train Acc: 0.9766939878463745, Val Acc: 0.9765572547912598, Val Precision: 0.9774578809738159, Val Recall: 0.9765572547912598\n",
      "Epoch: 138/500, Loss: 0.0001208522153319791,Train Acc: 0.9767118096351624, Val Acc: 0.9765760898590088, Val Precision: 0.9774739742279053, Val Recall: 0.9765760898590088\n",
      "Epoch: 139/500, Loss: 7.399715104838833e-05,Train Acc: 0.9767292737960815, Val Acc: 0.9765946865081787, Val Precision: 0.977489709854126, Val Recall: 0.9765946865081787\n",
      "Epoch: 140/500, Loss: 0.00013949946151115,Train Acc: 0.9767465591430664, Val Acc: 0.9766130447387695, Val Precision: 0.9775053262710571, Val Recall: 0.9766130447387695\n",
      "Epoch: 141/500, Loss: 6.389550253516063e-05,Train Acc: 0.9767636060714722, Val Acc: 0.9766310453414917, Val Precision: 0.9775205850601196, Val Recall: 0.9766310453414917\n",
      "Epoch: 142/500, Loss: 0.0002192111569456756,Train Acc: 0.976780354976654, Val Acc: 0.9766489267349243, Val Precision: 0.9775357246398926, Val Recall: 0.9766489267349243\n",
      "Epoch: 143/500, Loss: 6.003721500746906e-05,Train Acc: 0.9767968654632568, Val Acc: 0.9766664505004883, Val Precision: 0.9775506258010864, Val Recall: 0.9766664505004883\n",
      "Epoch: 144/500, Loss: 8.638335566502064e-05,Train Acc: 0.9768131971359253, Val Acc: 0.9766837954521179, Val Precision: 0.9775652885437012, Val Recall: 0.9766837954521179\n",
      "Epoch: 145/500, Loss: 7.227609603432938e-05,Train Acc: 0.9768292903900146, Val Acc: 0.9767008423805237, Val Precision: 0.9775798320770264, Val Recall: 0.9767008423805237\n",
      "Epoch: 146/500, Loss: 7.845615618862212e-05,Train Acc: 0.9768451452255249, Val Acc: 0.9767177104949951, Val Precision: 0.9775941371917725, Val Recall: 0.9767177104949951\n",
      "Epoch: 147/500, Loss: 9.520467574475333e-05,Train Acc: 0.9768608212471008, Val Acc: 0.9767342805862427, Val Precision: 0.9776082038879395, Val Recall: 0.9767342805862427\n",
      "Epoch: 148/500, Loss: 0.00013002849300391972,Train Acc: 0.9768762588500977, Val Acc: 0.9767506718635559, Val Precision: 0.9776221513748169, Val Recall: 0.9767506718635559\n",
      "Epoch: 149/500, Loss: 0.00011143297160742804,Train Acc: 0.9768915176391602, Val Acc: 0.97676682472229, Val Precision: 0.9776358604431152, Val Recall: 0.97676682472229\n",
      "Epoch: 150/500, Loss: 0.00013180539826862514,Train Acc: 0.9769065380096436, Val Acc: 0.9767827987670898, Val Precision: 0.9776493310928345, Val Recall: 0.9767827987670898\n",
      "Epoch: 151/500, Loss: 7.470790296792984e-05,Train Acc: 0.9769213199615479, Val Acc: 0.9767985343933105, Val Precision: 0.9776626825332642, Val Recall: 0.9767985343933105\n",
      "Epoch: 152/500, Loss: 3.7345274904510006e-05,Train Acc: 0.9769359827041626, Val Acc: 0.9768140316009521, Val Precision: 0.9776759147644043, Val Recall: 0.9768140316009521\n",
      "Epoch: 153/500, Loss: 3.56579948856961e-05,Train Acc: 0.9769504070281982, Val Acc: 0.9768294095993042, Val Precision: 0.9776889085769653, Val Recall: 0.9768294095993042\n",
      "Epoch: 154/500, Loss: 7.720919529674575e-05,Train Acc: 0.9769647121429443, Val Acc: 0.9768444895744324, Val Precision: 0.977701723575592, Val Recall: 0.9768444895744324\n",
      "Epoch: 155/500, Loss: 8.138163684634492e-05,Train Acc: 0.9769787788391113, Val Acc: 0.9768593907356262, Val Precision: 0.9777144193649292, Val Recall: 0.9768593907356262\n",
      "Epoch: 156/500, Loss: 7.39231109037064e-05,Train Acc: 0.976992666721344, Val Acc: 0.9768741130828857, Val Precision: 0.977726936340332, Val Recall: 0.9768741130828857\n",
      "Epoch: 157/500, Loss: 8.865520794643089e-05,Train Acc: 0.9770063757896423, Val Acc: 0.9768886566162109, Val Precision: 0.9777392148971558, Val Recall: 0.9768886566162109\n",
      "Epoch: 158/500, Loss: 6.098068843130022e-05,Train Acc: 0.9770199060440063, Val Acc: 0.9769030809402466, Val Precision: 0.9777514338493347, Val Recall: 0.9769030809402466\n",
      "Epoch: 159/500, Loss: 3.053269028896466e-05,Train Acc: 0.977033257484436, Val Acc: 0.9769172668457031, Val Precision: 0.9777634143829346, Val Recall: 0.9769172668457031\n",
      "Epoch: 160/500, Loss: 8.732134301681072e-05,Train Acc: 0.9770464897155762, Val Acc: 0.9769312143325806, Val Precision: 0.9777753353118896, Val Recall: 0.9769312143325806\n",
      "Epoch: 161/500, Loss: 3.262946484028362e-05,Train Acc: 0.977059543132782, Val Acc: 0.9769450426101685, Val Precision: 0.9777870774269104, Val Recall: 0.9769450426101685\n",
      "Epoch: 162/500, Loss: 4.7812012780923396e-05,Train Acc: 0.9770724177360535, Val Acc: 0.976958692073822, Val Precision: 0.9777986407279968, Val Recall: 0.976958692073822\n",
      "Epoch: 163/500, Loss: 2.788595884339884e-05,Train Acc: 0.9770851135253906, Val Acc: 0.9769721627235413, Val Precision: 0.9778101444244385, Val Recall: 0.9769721627235413\n",
      "Epoch: 164/500, Loss: 5.678674642695114e-05,Train Acc: 0.9770976901054382, Val Acc: 0.9769854545593262, Val Precision: 0.977821409702301, Val Recall: 0.9769854545593262\n",
      "Epoch: 165/500, Loss: 6.852447404526174e-05,Train Acc: 0.9771100878715515, Val Acc: 0.9769986867904663, Val Precision: 0.977832555770874, Val Recall: 0.9769986867904663\n",
      "Epoch: 166/500, Loss: 3.822050348389894e-05,Train Acc: 0.9771223664283752, Val Acc: 0.9770116806030273, Val Precision: 0.9778436422348022, Val Recall: 0.9770116806030273\n",
      "Epoch: 167/500, Loss: 6.56132324365899e-05,Train Acc: 0.9771344661712646, Val Acc: 0.977024495601654, Val Precision: 0.9778544902801514, Val Recall: 0.977024495601654\n",
      "Epoch: 168/500, Loss: 4.7406985686393455e-05,Train Acc: 0.9771464467048645, Val Acc: 0.9770371913909912, Val Precision: 0.9778652787208557, Val Recall: 0.9770371913909912\n",
      "Epoch: 169/500, Loss: 5.370387953007594e-05,Train Acc: 0.9771583080291748, Val Acc: 0.977049708366394, Val Precision: 0.9778759479522705, Val Recall: 0.977049708366394\n",
      "Epoch: 170/500, Loss: 6.132525595603511e-05,Train Acc: 0.9771699905395508, Val Acc: 0.9770621061325073, Val Precision: 0.977886438369751, Val Recall: 0.9770621061325073\n",
      "Epoch: 171/500, Loss: 2.6816167519427836e-05,Train Acc: 0.9771815538406372, Val Acc: 0.977074384689331, Val Precision: 0.9778968095779419, Val Recall: 0.977074384689331\n",
      "Epoch: 172/500, Loss: 7.86443124525249e-05,Train Acc: 0.9771929979324341, Val Acc: 0.9770864248275757, Val Precision: 0.9779070615768433, Val Recall: 0.9770864248275757\n",
      "Epoch: 173/500, Loss: 3.3125939808087423e-05,Train Acc: 0.9772042036056519, Val Acc: 0.9770984649658203, Val Precision: 0.9779171943664551, Val Recall: 0.9770984649658203\n",
      "Epoch: 174/500, Loss: 4.6269164158729836e-05,Train Acc: 0.9772154092788696, Val Acc: 0.9771102666854858, Val Precision: 0.9779272675514221, Val Recall: 0.9771102666854858\n",
      "Epoch: 175/500, Loss: 4.4552205508807674e-05,Train Acc: 0.9772264361381531, Val Acc: 0.9771219491958618, Val Precision: 0.9779371619224548, Val Recall: 0.9771219491958618\n",
      "Epoch: 176/500, Loss: 5.8845984312938526e-05,Train Acc: 0.977237343788147, Val Acc: 0.9771334528923035, Val Precision: 0.9779469966888428, Val Recall: 0.9771334528923035\n",
      "Epoch: 177/500, Loss: 3.930159437004477e-05,Train Acc: 0.9772480726242065, Val Acc: 0.9771448969841003, Val Precision: 0.9779566526412964, Val Recall: 0.9771448969841003\n",
      "Epoch: 178/500, Loss: 4.4640917622018605e-05,Train Acc: 0.9772588014602661, Val Acc: 0.9771561622619629, Val Precision: 0.9779662489891052, Val Recall: 0.9771561622619629\n",
      "Epoch: 179/500, Loss: 6.0315695009194314e-05,Train Acc: 0.9772692918777466, Val Acc: 0.9771673679351807, Val Precision: 0.9779757261276245, Val Recall: 0.9771673679351807\n",
      "Epoch: 180/500, Loss: 8.293196151498705e-05,Train Acc: 0.9772834777832031, Val Acc: 0.977182149887085, Val Precision: 0.9779874682426453, Val Recall: 0.977182149887085\n",
      "Epoch: 181/500, Loss: 3.730569005711004e-05,Train Acc: 0.9772937297821045, Val Acc: 0.9771930575370789, Val Precision: 0.9779967069625854, Val Recall: 0.9771930575370789\n",
      "Epoch: 182/500, Loss: 1.8873724911827594e-05,Train Acc: 0.9773039817810059, Val Acc: 0.9772038459777832, Val Precision: 0.9780058860778809, Val Recall: 0.9772038459777832\n",
      "Epoch: 183/500, Loss: 6.636338366661221e-05,Train Acc: 0.9773139953613281, Val Acc: 0.9772144556045532, Val Precision: 0.9780148863792419, Val Recall: 0.9772144556045532\n",
      "Epoch: 184/500, Loss: 1.5593033822369762e-05,Train Acc: 0.9773240089416504, Val Acc: 0.9772250652313232, Val Precision: 0.978023886680603, Val Recall: 0.9772250652313232\n",
      "Epoch: 185/500, Loss: 4.7244106099242344e-05,Train Acc: 0.9773337841033936, Val Acc: 0.9772354364395142, Val Precision: 0.9780327081680298, Val Recall: 0.9772354364395142\n",
      "Epoch: 186/500, Loss: 3.325600118841976e-05,Train Acc: 0.9773435592651367, Val Acc: 0.9772457480430603, Val Precision: 0.9780414700508118, Val Recall: 0.9772457480430603\n",
      "Epoch: 187/500, Loss: 2.3255082851392217e-05,Train Acc: 0.9773532152175903, Val Acc: 0.9772559404373169, Val Precision: 0.9780501127243042, Val Recall: 0.9772559404373169\n",
      "Epoch: 188/500, Loss: 3.616445974330418e-05,Train Acc: 0.9773627519607544, Val Acc: 0.9772660732269287, Val Precision: 0.9780586957931519, Val Recall: 0.9772660732269287\n",
      "Epoch: 189/500, Loss: 4.659168189391494e-05,Train Acc: 0.9773721694946289, Val Acc: 0.977276086807251, Val Precision: 0.97806715965271, Val Recall: 0.977276086807251\n",
      "Epoch: 190/500, Loss: 5.045265788794495e-05,Train Acc: 0.9773814678192139, Val Acc: 0.9772859811782837, Val Precision: 0.9780756235122681, Val Recall: 0.9772859811782837\n",
      "Epoch: 191/500, Loss: 4.6829893108224496e-05,Train Acc: 0.9773907661437988, Val Acc: 0.9772957563400269, Val Precision: 0.9780838489532471, Val Recall: 0.9772957563400269\n",
      "Epoch: 192/500, Loss: 1.638493631617166e-05,Train Acc: 0.9774034023284912, Val Acc: 0.9773088693618774, Val Precision: 0.9780942797660828, Val Recall: 0.9773088693618774\n",
      "Epoch: 193/500, Loss: 4.8344798415200785e-05,Train Acc: 0.9774124622344971, Val Acc: 0.9773184657096863, Val Precision: 0.978102445602417, Val Recall: 0.9773184657096863\n",
      "Epoch: 194/500, Loss: 1.9079598132520914e-05,Train Acc: 0.9774214029312134, Val Acc: 0.9773279428482056, Val Precision: 0.9781104326248169, Val Recall: 0.9773279428482056\n",
      "Epoch: 195/500, Loss: 1.9397451978875324e-05,Train Acc: 0.9774302244186401, Val Acc: 0.9773373007774353, Val Precision: 0.9781184196472168, Val Recall: 0.9773373007774353\n",
      "Epoch: 196/500, Loss: 2.4529530492145568e-05,Train Acc: 0.9774389266967773, Val Acc: 0.9773465394973755, Val Precision: 0.9781262874603271, Val Recall: 0.9773465394973755\n",
      "Epoch: 197/500, Loss: 3.940403985325247e-05,Train Acc: 0.9774510860443115, Val Acc: 0.9773591756820679, Val Precision: 0.9781361818313599, Val Recall: 0.9773591756820679\n",
      "Epoch: 198/500, Loss: 5.1955910748802125e-05,Train Acc: 0.9774596095085144, Val Acc: 0.9773682355880737, Val Precision: 0.9781439304351807, Val Recall: 0.9773682355880737\n",
      "Epoch: 199/500, Loss: 4.669946793001145e-05,Train Acc: 0.9774680733680725, Val Acc: 0.97737717628479, Val Precision: 0.9781515002250671, Val Recall: 0.97737717628479\n",
      "Epoch: 200/500, Loss: 2.353006311750505e-05,Train Acc: 0.9774798154830933, Val Acc: 0.9773894548416138, Val Precision: 0.9781611561775208, Val Recall: 0.9773894548416138\n",
      "Epoch: 201/500, Loss: 2.8636119168368168e-05,Train Acc: 0.9774914979934692, Val Acc: 0.977401614189148, Val Precision: 0.9781706929206848, Val Recall: 0.977401614189148\n",
      "Epoch: 202/500, Loss: 1.6070634956122376e-05,Train Acc: 0.9775030016899109, Val Acc: 0.9774135947227478, Val Precision: 0.9781801700592041, Val Recall: 0.9774135947227478\n",
      "Epoch: 203/500, Loss: 6.587382813449949e-05,Train Acc: 0.9775144457817078, Val Acc: 0.9774255156517029, Val Precision: 0.9781895279884338, Val Recall: 0.9774255156517029\n",
      "Epoch: 204/500, Loss: 4.268479096936062e-05,Train Acc: 0.9775223731994629, Val Acc: 0.977433979511261, Val Precision: 0.9781967401504517, Val Recall: 0.977433979511261\n",
      "Epoch: 205/500, Loss: 3.268228465458378e-05,Train Acc: 0.9775336384773254, Val Acc: 0.977445662021637, Val Precision: 0.9782059192657471, Val Recall: 0.977445662021637\n",
      "Epoch: 206/500, Loss: 3.168448165524751e-05,Train Acc: 0.977541446685791, Val Acc: 0.9774539470672607, Val Precision: 0.9782130122184753, Val Recall: 0.9774539470672607\n",
      "Epoch: 207/500, Loss: 3.4895167573267827e-06,Train Acc: 0.9775524139404297, Val Acc: 0.9774653911590576, Val Precision: 0.9782220125198364, Val Recall: 0.9774653911590576\n",
      "Epoch: 208/500, Loss: 2.667202534212265e-05,Train Acc: 0.9775601625442505, Val Acc: 0.9774734973907471, Val Precision: 0.9782289266586304, Val Recall: 0.9774734973907471\n",
      "Epoch: 209/500, Loss: 3.10675532091409e-05,Train Acc: 0.9775709509849548, Val Acc: 0.9774848222732544, Val Precision: 0.9782377481460571, Val Recall: 0.9774848222732544\n",
      "Epoch: 210/500, Loss: 2.589939504105132e-05,Train Acc: 0.9775784015655518, Val Acc: 0.9774926900863647, Val Precision: 0.9782445430755615, Val Recall: 0.9774926900863647\n",
      "Epoch: 211/500, Loss: 2.9933371479273774e-05,Train Acc: 0.9775858521461487, Val Acc: 0.9775005578994751, Val Precision: 0.9782512784004211, Val Recall: 0.9775005578994751\n",
      "Epoch: 212/500, Loss: 3.148263203911483e-05,Train Acc: 0.9775964021682739, Val Acc: 0.9775115847587585, Val Precision: 0.9782599210739136, Val Recall: 0.9775115847587585\n",
      "Epoch: 213/500, Loss: 3.375496817170642e-05,Train Acc: 0.9776036739349365, Val Acc: 0.9775192737579346, Val Precision: 0.9782664775848389, Val Recall: 0.9775192737579346\n",
      "Epoch: 214/500, Loss: 4.2480412957957014e-05,Train Acc: 0.9776140451431274, Val Acc: 0.9775300621986389, Val Precision: 0.978274941444397, Val Recall: 0.9775300621986389\n",
      "Epoch: 215/500, Loss: 1.4062437912798487e-05,Train Acc: 0.9776211380958557, Val Acc: 0.9775376319885254, Val Precision: 0.9782813787460327, Val Recall: 0.9775376319885254\n",
      "Epoch: 216/500, Loss: 1.1046427971450612e-05,Train Acc: 0.977628231048584, Val Acc: 0.9775451421737671, Val Precision: 0.9782877564430237, Val Recall: 0.9775451421737671\n",
      "Epoch: 217/500, Loss: 2.112044967361726e-05,Train Acc: 0.977638304233551, Val Acc: 0.9775556325912476, Val Precision: 0.9782960414886475, Val Recall: 0.9775556325912476\n",
      "Epoch: 218/500, Loss: 2.2618885850533843e-05,Train Acc: 0.9776483178138733, Val Acc: 0.9775660037994385, Val Precision: 0.9783042669296265, Val Recall: 0.9775660037994385\n",
      "Epoch: 219/500, Loss: 1.801432154024951e-05,Train Acc: 0.977658212184906, Val Acc: 0.9775763750076294, Val Precision: 0.9783123731613159, Val Recall: 0.9775763750076294\n",
      "Epoch: 220/500, Loss: 2.2445881768362597e-05,Train Acc: 0.9776650071144104, Val Acc: 0.9775835275650024, Val Precision: 0.978318452835083, Val Recall: 0.9775835275650024\n",
      "Epoch: 221/500, Loss: 2.1704634491470642e-05,Train Acc: 0.9776716828346252, Val Acc: 0.9775906205177307, Val Precision: 0.9783245325088501, Val Recall: 0.9775906205177307\n",
      "Epoch: 222/500, Loss: 6.48775539957569e-06,Train Acc: 0.9776813983917236, Val Acc: 0.9776006937026978, Val Precision: 0.9783324599266052, Val Recall: 0.9776006937026978\n",
      "Epoch: 223/500, Loss: 2.976539690280333e-05,Train Acc: 0.9776909351348877, Val Acc: 0.97761070728302, Val Precision: 0.9783402681350708, Val Recall: 0.97761070728302\n",
      "Epoch: 224/500, Loss: 3.4523833164712414e-05,Train Acc: 0.9777004718780518, Val Acc: 0.9776206016540527, Val Precision: 0.9783480167388916, Val Recall: 0.9776206016540527\n",
      "Epoch: 225/500, Loss: 2.734055306063965e-05,Train Acc: 0.9777069091796875, Val Acc: 0.9776273965835571, Val Precision: 0.9783538579940796, Val Recall: 0.9776273965835571\n",
      "Epoch: 226/500, Loss: 2.789003701764159e-05,Train Acc: 0.9777162075042725, Val Acc: 0.9776371121406555, Val Precision: 0.9783614873886108, Val Recall: 0.9776371121406555\n",
      "Epoch: 227/500, Loss: 1.5290428564185277e-05,Train Acc: 0.9777225255966187, Val Acc: 0.9776437878608704, Val Precision: 0.9783672094345093, Val Recall: 0.9776437878608704\n",
      "Epoch: 228/500, Loss: 2.4887600375222974e-05,Train Acc: 0.9777317047119141, Val Acc: 0.9776533842086792, Val Precision: 0.978374719619751, Val Recall: 0.9776533842086792\n",
      "Epoch: 229/500, Loss: 2.6013716706074774e-05,Train Acc: 0.9777408838272095, Val Acc: 0.9776628613471985, Val Precision: 0.9783821702003479, Val Recall: 0.9776628613471985\n",
      "Epoch: 230/500, Loss: 3.452149758231826e-05,Train Acc: 0.9777498841285706, Val Acc: 0.9776722192764282, Val Precision: 0.9783895611763, Val Recall: 0.9776722192764282\n",
      "Epoch: 231/500, Loss: 1.1750540579669178e-05,Train Acc: 0.9777559041976929, Val Acc: 0.977678656578064, Val Precision: 0.9783950448036194, Val Recall: 0.977678656578064\n",
      "Epoch: 232/500, Loss: 2.0805544409085996e-05,Train Acc: 0.9777648448944092, Val Acc: 0.9776879549026489, Val Precision: 0.978402316570282, Val Recall: 0.9776879549026489\n",
      "Epoch: 233/500, Loss: 1.4585929420718458e-05,Train Acc: 0.9777736663818359, Val Acc: 0.9776971340179443, Val Precision: 0.9784095287322998, Val Recall: 0.9776971340179443\n",
      "Epoch: 234/500, Loss: 1.7959642718778923e-05,Train Acc: 0.9777823686599731, Val Acc: 0.9777061939239502, Val Precision: 0.9784166812896729, Val Recall: 0.9777061939239502\n",
      "Epoch: 235/500, Loss: 1.1931190783798229e-05,Train Acc: 0.9777910709381104, Val Acc: 0.977715253829956, Val Precision: 0.9784237146377563, Val Recall: 0.977715253829956\n",
      "Epoch: 236/500, Loss: 1.4874212865834124e-05,Train Acc: 0.977799654006958, Val Acc: 0.9777241945266724, Val Precision: 0.9784307479858398, Val Recall: 0.9777241945266724\n",
      "Epoch: 237/500, Loss: 1.4998187907622196e-05,Train Acc: 0.9778081774711609, Val Acc: 0.9777330160140991, Val Precision: 0.9784376621246338, Val Recall: 0.9777330160140991\n",
      "Epoch: 238/500, Loss: 1.9499055269989185e-05,Train Acc: 0.977816641330719, Val Acc: 0.9777418375015259, Val Precision: 0.9784445762634277, Val Recall: 0.9777418375015259\n",
      "Epoch: 239/500, Loss: 2.2929856640985236e-05,Train Acc: 0.9778221845626831, Val Acc: 0.9777477383613586, Val Precision: 0.9784497022628784, Val Recall: 0.9777477383613586\n",
      "Epoch: 240/500, Loss: 1.1429179721744731e-05,Train Acc: 0.9778305292129517, Val Acc: 0.9777563810348511, Val Precision: 0.9784564971923828, Val Recall: 0.9777563810348511\n",
      "Epoch: 241/500, Loss: 3.857899628201267e-06,Train Acc: 0.9778387546539307, Val Acc: 0.9777650237083435, Val Precision: 0.9784631729125977, Val Recall: 0.9777650237083435\n",
      "Epoch: 242/500, Loss: 1.4893239494995214e-05,Train Acc: 0.9778469800949097, Val Acc: 0.9777735471725464, Val Precision: 0.9784698486328125, Val Recall: 0.9777735471725464\n",
      "Epoch: 243/500, Loss: 1.1793982594099361e-05,Train Acc: 0.9778523445129395, Val Acc: 0.9777792096138, Val Precision: 0.9784747362136841, Val Recall: 0.9777792096138\n",
      "Epoch: 244/500, Loss: 1.6211926777032204e-05,Train Acc: 0.9778603315353394, Val Acc: 0.9777876138687134, Val Precision: 0.9784812927246094, Val Recall: 0.9777876138687134\n",
      "Epoch: 245/500, Loss: 1.640636401134543e-05,Train Acc: 0.9778683185577393, Val Acc: 0.9777958989143372, Val Precision: 0.9784878492355347, Val Recall: 0.9777958989143372\n",
      "Epoch: 246/500, Loss: 9.041402336151805e-06,Train Acc: 0.9778763055801392, Val Acc: 0.9778041839599609, Val Precision: 0.9784942865371704, Val Recall: 0.9778041839599609\n",
      "Epoch: 247/500, Loss: 2.240638787043281e-05,Train Acc: 0.9778841733932495, Val Acc: 0.9778123497962952, Val Precision: 0.9785007238388062, Val Recall: 0.9778123497962952\n",
      "Epoch: 248/500, Loss: 1.0699594895413611e-05,Train Acc: 0.9778919219970703, Val Acc: 0.9778204560279846, Val Precision: 0.9785071015357971, Val Recall: 0.9778204560279846\n",
      "Epoch: 249/500, Loss: 2.6862981030717492e-05,Train Acc: 0.9778996706008911, Val Acc: 0.9778285026550293, Val Precision: 0.9785134196281433, Val Recall: 0.9778285026550293\n",
      "Epoch: 250/500, Loss: 1.0096462574438192e-05,Train Acc: 0.9779074192047119, Val Acc: 0.9778364896774292, Val Precision: 0.9785196781158447, Val Recall: 0.9778364896774292\n",
      "Epoch: 251/500, Loss: 8.022901056392584e-06,Train Acc: 0.9779149889945984, Val Acc: 0.9778444170951843, Val Precision: 0.9785258769989014, Val Recall: 0.9778444170951843\n",
      "Epoch: 252/500, Loss: 1.013943983707577e-05,Train Acc: 0.9779225587844849, Val Acc: 0.9778522849082947, Val Precision: 0.978532075881958, Val Recall: 0.9778522849082947\n",
      "Epoch: 253/500, Loss: 1.8873141016229056e-05,Train Acc: 0.9779300689697266, Val Acc: 0.9778600931167603, Val Precision: 0.9785381555557251, Val Recall: 0.9778600931167603\n",
      "Epoch: 254/500, Loss: 8.600759429100435e-06,Train Acc: 0.9779374599456787, Val Acc: 0.977867841720581, Val Precision: 0.9785442352294922, Val Recall: 0.977867841720581\n",
      "Epoch: 255/500, Loss: 1.4675874808744993e-05,Train Acc: 0.9779448509216309, Val Acc: 0.9778755307197571, Val Precision: 0.9785501956939697, Val Recall: 0.9778755307197571\n",
      "Epoch: 256/500, Loss: 1.575660462549422e-05,Train Acc: 0.977952241897583, Val Acc: 0.9778831005096436, Val Precision: 0.9785561561584473, Val Recall: 0.9778831005096436\n",
      "Epoch: 257/500, Loss: 7.784532499499619e-06,Train Acc: 0.9779595136642456, Val Acc: 0.9778907299041748, Val Precision: 0.9785621166229248, Val Recall: 0.9778907299041748\n",
      "Epoch: 258/500, Loss: 8.001231435628142e-06,Train Acc: 0.9779666662216187, Val Acc: 0.9778981804847717, Val Precision: 0.9785680174827576, Val Recall: 0.9778981804847717\n",
      "Epoch: 259/500, Loss: 7.972232197062112e-06,Train Acc: 0.9779738187789917, Val Acc: 0.9779056310653687, Val Precision: 0.9785737991333008, Val Recall: 0.9779056310653687\n",
      "Epoch: 260/500, Loss: 8.88266549736727e-06,Train Acc: 0.9779809713363647, Val Acc: 0.9779130220413208, Val Precision: 0.9785796403884888, Val Recall: 0.9779130220413208\n",
      "Epoch: 261/500, Loss: 6.419107648980571e-06,Train Acc: 0.9779880046844482, Val Acc: 0.9779203534126282, Val Precision: 0.9785853624343872, Val Recall: 0.9779203534126282\n",
      "Epoch: 262/500, Loss: 1.4929003555153031e-05,Train Acc: 0.9779949188232422, Val Acc: 0.977927565574646, Val Precision: 0.9785910844802856, Val Recall: 0.977927565574646\n",
      "Epoch: 263/500, Loss: 7.614806236233562e-06,Train Acc: 0.9780018925666809, Val Acc: 0.9779348373413086, Val Precision: 0.9785966873168945, Val Recall: 0.9779348373413086\n",
      "Epoch: 264/500, Loss: 9.554602002026513e-06,Train Acc: 0.978010356426239, Val Acc: 0.9779435396194458, Val Precision: 0.9786048531532288, Val Recall: 0.9779435396194458\n",
      "Epoch: 265/500, Loss: 1.4481574908131734e-05,Train Acc: 0.9780187010765076, Val Acc: 0.977952241897583, Val Precision: 0.9786129593849182, Val Recall: 0.977952241897583\n",
      "Epoch: 266/500, Loss: 3.7351526316342643e-06,Train Acc: 0.978025496006012, Val Acc: 0.9779592752456665, Val Precision: 0.9786184430122375, Val Recall: 0.9779592752456665\n",
      "Epoch: 267/500, Loss: 2.1691585061489604e-05,Train Acc: 0.9780337810516357, Val Acc: 0.9779677987098694, Val Precision: 0.9786264300346375, Val Recall: 0.9779677987098694\n",
      "Epoch: 268/500, Loss: 8.618920219305437e-06,Train Acc: 0.9780404567718506, Val Acc: 0.9779747128486633, Val Precision: 0.978631854057312, Val Recall: 0.9779747128486633\n",
      "Epoch: 269/500, Loss: 1.4047864169697277e-05,Train Acc: 0.97804856300354, Val Acc: 0.9779831171035767, Val Precision: 0.9786397218704224, Val Recall: 0.9779831171035767\n",
      "Epoch: 270/500, Loss: 1.195661479869159e-05,Train Acc: 0.9780566692352295, Val Acc: 0.9779914617538452, Val Precision: 0.9786474704742432, Val Recall: 0.9779914617538452\n",
      "Epoch: 271/500, Loss: 2.026539277721895e-06,Train Acc: 0.9780646562576294, Val Acc: 0.977999746799469, Val Precision: 0.978655219078064, Val Recall: 0.977999746799469\n",
      "Epoch: 272/500, Loss: 9.691870218375698e-06,Train Acc: 0.9780726432800293, Val Acc: 0.978007972240448, Val Precision: 0.9786629676818848, Val Recall: 0.978007972240448\n",
      "Epoch: 273/500, Loss: 1.7753776774043217e-05,Train Acc: 0.9780790209770203, Val Acc: 0.9780145883560181, Val Precision: 0.9786680936813354, Val Recall: 0.9780145883560181\n",
      "Epoch: 274/500, Loss: 6.783869139326271e-06,Train Acc: 0.9780868291854858, Val Acc: 0.9780226945877075, Val Precision: 0.9786757230758667, Val Recall: 0.9780226945877075\n",
      "Epoch: 275/500, Loss: 8.477896699332632e-06,Train Acc: 0.9780946373939514, Val Acc: 0.978030800819397, Val Precision: 0.9786832332611084, Val Recall: 0.978030800819397\n",
      "Epoch: 276/500, Loss: 5.11145935888635e-06,Train Acc: 0.9781023859977722, Val Acc: 0.9780387878417969, Val Precision: 0.9786907434463501, Val Recall: 0.9780387878417969\n",
      "Epoch: 277/500, Loss: 4.276999334251741e-06,Train Acc: 0.9781100749969482, Val Acc: 0.9780466556549072, Val Precision: 0.9786981344223022, Val Recall: 0.9780466556549072\n",
      "Epoch: 278/500, Loss: 1.2014436833851505e-05,Train Acc: 0.9781177043914795, Val Acc: 0.9780545234680176, Val Precision: 0.9787054657936096, Val Recall: 0.9780545234680176\n",
      "Epoch: 279/500, Loss: 5.823082574352156e-06,Train Acc: 0.9781252145767212, Val Acc: 0.9780623912811279, Val Precision: 0.978712797164917, Val Recall: 0.9780623912811279\n",
      "Epoch: 280/500, Loss: 9.846962711890228e-06,Train Acc: 0.9781327247619629, Val Acc: 0.9780701398849487, Val Precision: 0.9787200689315796, Val Recall: 0.9780701398849487\n",
      "Epoch: 281/500, Loss: 1.492941828473704e-05,Train Acc: 0.9781402349472046, Val Acc: 0.9780778884887695, Val Precision: 0.9787272810935974, Val Recall: 0.9780778884887695\n",
      "Epoch: 282/500, Loss: 7.0007099566282704e-06,Train Acc: 0.9781476259231567, Val Acc: 0.9780855178833008, Val Precision: 0.9787343740463257, Val Recall: 0.9780855178833008\n",
      "Epoch: 283/500, Loss: 6.014531209075358e-06,Train Acc: 0.9781550168991089, Val Acc: 0.9780930876731873, Val Precision: 0.9787415266036987, Val Recall: 0.9780930876731873\n",
      "Epoch: 284/500, Loss: 1.7237585780094378e-05,Train Acc: 0.9781622886657715, Val Acc: 0.9781006574630737, Val Precision: 0.9787485599517822, Val Recall: 0.9781006574630737\n",
      "Epoch: 285/500, Loss: 6.932052656338783e-06,Train Acc: 0.9781695604324341, Val Acc: 0.9781081676483154, Val Precision: 0.9787555932998657, Val Recall: 0.9781081676483154\n",
      "Epoch: 286/500, Loss: 7.116309461707715e-06,Train Acc: 0.9781767129898071, Val Acc: 0.9781155586242676, Val Precision: 0.9787625074386597, Val Recall: 0.9781155586242676\n",
      "Epoch: 287/500, Loss: 1.1971041203651112e-05,Train Acc: 0.978183925151825, Val Acc: 0.9781229496002197, Val Precision: 0.9787694215774536, Val Recall: 0.9781229496002197\n",
      "Epoch: 288/500, Loss: 1.2213276022521313e-05,Train Acc: 0.9781910181045532, Val Acc: 0.9781302809715271, Val Precision: 0.9787763357162476, Val Recall: 0.9781302809715271\n",
      "Epoch: 289/500, Loss: 9.38465200306382e-06,Train Acc: 0.9781966209411621, Val Acc: 0.9781361818313599, Val Precision: 0.9787808060646057, Val Recall: 0.9781361818313599\n",
      "Epoch: 290/500, Loss: 4.287846877559787e-06,Train Acc: 0.9782036542892456, Val Acc: 0.9781433939933777, Val Precision: 0.9787875413894653, Val Recall: 0.9781433939933777\n",
      "Epoch: 291/500, Loss: 6.957390723982826e-06,Train Acc: 0.9782106280326843, Val Acc: 0.9781506061553955, Val Precision: 0.9787943363189697, Val Recall: 0.9781506061553955\n",
      "Epoch: 292/500, Loss: 5.526898348762188e-06,Train Acc: 0.9782175421714783, Val Acc: 0.9781577587127686, Val Precision: 0.9788010120391846, Val Recall: 0.9781577587127686\n",
      "Epoch: 293/500, Loss: 7.0079236138553824e-06,Train Acc: 0.9782243967056274, Val Acc: 0.978164792060852, Val Precision: 0.9788076281547546, Val Recall: 0.978164792060852\n",
      "Epoch: 294/500, Loss: 2.246894837298896e-06,Train Acc: 0.9782311916351318, Val Acc: 0.9781718254089355, Val Precision: 0.9788142442703247, Val Recall: 0.9781718254089355\n",
      "Epoch: 295/500, Loss: 6.9645657276851125e-06,Train Acc: 0.9782379865646362, Val Acc: 0.978178858757019, Val Precision: 0.9788207411766052, Val Recall: 0.978178858757019\n",
      "Epoch: 296/500, Loss: 2.5069512048503384e-06,Train Acc: 0.9782447218894958, Val Acc: 0.978185772895813, Val Precision: 0.9788272380828857, Val Recall: 0.978185772895813\n",
      "Epoch: 297/500, Loss: 4.649084985430818e-06,Train Acc: 0.9782513976097107, Val Acc: 0.9781926870346069, Val Precision: 0.9788336753845215, Val Recall: 0.9781926870346069\n",
      "Epoch: 298/500, Loss: 1.0370930795033928e-05,Train Acc: 0.9782580137252808, Val Acc: 0.9781996011734009, Val Precision: 0.9788401126861572, Val Recall: 0.9781996011734009\n",
      "Epoch: 299/500, Loss: 3.272770300100092e-06,Train Acc: 0.9782646298408508, Val Acc: 0.9782063961029053, Val Precision: 0.978846549987793, Val Recall: 0.9782063961029053\n",
      "Epoch: 300/500, Loss: 4.764672212331789e-06,Train Acc: 0.9782711863517761, Val Acc: 0.9782131314277649, Val Precision: 0.9788528680801392, Val Recall: 0.9782131314277649\n",
      "Epoch: 301/500, Loss: 6.180693617352517e-06,Train Acc: 0.9782776832580566, Val Acc: 0.9782198667526245, Val Precision: 0.9788590669631958, Val Recall: 0.9782198667526245\n",
      "Epoch: 302/500, Loss: 4.161430751992157e-06,Train Acc: 0.9782841801643372, Val Acc: 0.9782265424728394, Val Precision: 0.978865385055542, Val Recall: 0.9782265424728394\n",
      "Epoch: 303/500, Loss: 2.5539461603329983e-06,Train Acc: 0.9782905578613281, Val Acc: 0.9782330989837646, Val Precision: 0.9788715839385986, Val Recall: 0.9782330989837646\n",
      "Epoch: 304/500, Loss: 5.967613105894998e-06,Train Acc: 0.9782969951629639, Val Acc: 0.9782397150993347, Val Precision: 0.9788777232170105, Val Recall: 0.9782397150993347\n",
      "Epoch: 305/500, Loss: 2.1313003344403114e-06,Train Acc: 0.9783033132553101, Val Acc: 0.97824627161026, Val Precision: 0.9788838624954224, Val Recall: 0.97824627161026\n",
      "Epoch: 306/500, Loss: 4.110853296879213e-06,Train Acc: 0.9783096313476562, Val Acc: 0.9782527685165405, Val Precision: 0.9788899421691895, Val Recall: 0.9782527685165405\n",
      "Epoch: 307/500, Loss: 2.5358849597978406e-06,Train Acc: 0.9783158302307129, Val Acc: 0.9782592058181763, Val Precision: 0.9788959622383118, Val Recall: 0.9782592058181763\n",
      "Epoch: 308/500, Loss: 4.85138343719882e-06,Train Acc: 0.9783220291137695, Val Acc: 0.978265643119812, Val Precision: 0.9789019823074341, Val Recall: 0.978265643119812\n",
      "Epoch: 309/500, Loss: 7.8387456596829e-06,Train Acc: 0.9783282279968262, Val Acc: 0.9782719612121582, Val Precision: 0.9789079427719116, Val Recall: 0.9782719612121582\n",
      "Epoch: 310/500, Loss: 3.6881824598822277e-06,Train Acc: 0.978334367275238, Val Acc: 0.9782783389091492, Val Precision: 0.9789138436317444, Val Recall: 0.9782783389091492\n",
      "Epoch: 311/500, Loss: 7.607598490722012e-06,Train Acc: 0.9783405065536499, Val Acc: 0.9782845973968506, Val Precision: 0.9789197444915771, Val Recall: 0.9782845973968506\n",
      "Epoch: 312/500, Loss: 8.264957614301238e-06,Train Acc: 0.9783464670181274, Val Acc: 0.978290855884552, Val Precision: 0.9789255857467651, Val Recall: 0.978290855884552\n",
      "Epoch: 313/500, Loss: 5.599210339823912e-07,Train Acc: 0.9783525466918945, Val Acc: 0.9782971143722534, Val Precision: 0.9789314270019531, Val Recall: 0.9782971143722534\n",
      "Epoch: 314/500, Loss: 1.6472358765895478e-06,Train Acc: 0.9783585071563721, Val Acc: 0.9783032536506653, Val Precision: 0.9789371490478516, Val Recall: 0.9783032536506653\n",
      "Epoch: 315/500, Loss: 4.219178208586527e-06,Train Acc: 0.9783644676208496, Val Acc: 0.9783093929290771, Val Precision: 0.97894287109375, Val Recall: 0.9783093929290771\n",
      "Epoch: 316/500, Loss: 4.327612714405404e-06,Train Acc: 0.9783703088760376, Val Acc: 0.9783154726028442, Val Precision: 0.9789485931396484, Val Recall: 0.9783154726028442\n",
      "Epoch: 317/500, Loss: 8.918839739635587e-06,Train Acc: 0.9783762097358704, Val Acc: 0.9783215522766113, Val Precision: 0.9789542555809021, Val Recall: 0.9783215522766113\n",
      "Epoch: 318/500, Loss: 4.652703410101822e-06,Train Acc: 0.9783820509910583, Val Acc: 0.9783275127410889, Val Precision: 0.9789599180221558, Val Recall: 0.9783275127410889\n",
      "Epoch: 319/500, Loss: 2.423902060399996e-06,Train Acc: 0.9783878326416016, Val Acc: 0.9783335328102112, Val Precision: 0.9789655208587646, Val Recall: 0.9783335328102112\n",
      "Epoch: 320/500, Loss: 4.977736807632027e-06,Train Acc: 0.9783935546875, Val Acc: 0.978339433670044, Val Precision: 0.9789710640907288, Val Recall: 0.978339433670044\n",
      "Epoch: 321/500, Loss: 2.272183564855368e-06,Train Acc: 0.9783992767333984, Val Acc: 0.9783453941345215, Val Precision: 0.9789766073226929, Val Recall: 0.9783453941345215\n",
      "Epoch: 322/500, Loss: 4.396210897539277e-06,Train Acc: 0.9784049987792969, Val Acc: 0.9783512353897095, Val Precision: 0.9789820909500122, Val Recall: 0.9783512353897095\n",
      "Epoch: 323/500, Loss: 7.08740526533802e-06,Train Acc: 0.9784106016159058, Val Acc: 0.9783570766448975, Val Precision: 0.9789875149726868, Val Recall: 0.9783570766448975\n",
      "Epoch: 324/500, Loss: 6.538343313877704e-06,Train Acc: 0.9784162640571594, Val Acc: 0.9783628582954407, Val Precision: 0.9789929389953613, Val Recall: 0.9783628582954407\n",
      "Epoch: 325/500, Loss: 5.255967607808998e-06,Train Acc: 0.9784218072891235, Val Acc: 0.9783686399459839, Val Precision: 0.9789983034133911, Val Recall: 0.9783686399459839\n",
      "Epoch: 326/500, Loss: 5.050076651968993e-06,Train Acc: 0.9784274101257324, Val Acc: 0.9783743619918823, Val Precision: 0.9790036678314209, Val Recall: 0.9783743619918823\n",
      "Epoch: 327/500, Loss: 6.661157840426313e-06,Train Acc: 0.9784328937530518, Val Acc: 0.978380024433136, Val Precision: 0.9790090322494507, Val Recall: 0.978380024433136\n",
      "Epoch: 328/500, Loss: 2.4491860131092835e-06,Train Acc: 0.9784383773803711, Val Acc: 0.9783856868743896, Val Precision: 0.9790142774581909, Val Recall: 0.9783856868743896\n",
      "Epoch: 329/500, Loss: 3.9952751649252605e-06,Train Acc: 0.9784438014030457, Val Acc: 0.9783912897109985, Val Precision: 0.9790195226669312, Val Recall: 0.9783912897109985\n",
      "Epoch: 330/500, Loss: 3.4642600894585485e-06,Train Acc: 0.9784492254257202, Val Acc: 0.9783968925476074, Val Precision: 0.9790247678756714, Val Recall: 0.9783968925476074\n",
      "Epoch: 331/500, Loss: 3.988059688708745e-06,Train Acc: 0.97845458984375, Val Acc: 0.9784024357795715, Val Precision: 0.9790300130844116, Val Recall: 0.9784024357795715\n",
      "Epoch: 332/500, Loss: 3.5762495826929808e-06,Train Acc: 0.9784599542617798, Val Acc: 0.9784079790115356, Val Precision: 0.9790351390838623, Val Recall: 0.9784079790115356\n",
      "Epoch: 333/500, Loss: 1.560547843837412e-06,Train Acc: 0.9784652590751648, Val Acc: 0.978413462638855, Val Precision: 0.979040265083313, Val Recall: 0.978413462638855\n",
      "Epoch: 334/500, Loss: 3.016325081262039e-06,Train Acc: 0.9784705638885498, Val Acc: 0.9784188866615295, Val Precision: 0.9790453910827637, Val Recall: 0.9784188866615295\n",
      "Epoch: 335/500, Loss: 1.578604496899061e-06,Train Acc: 0.97847580909729, Val Acc: 0.9784243106842041, Val Precision: 0.9790503978729248, Val Recall: 0.9784243106842041\n",
      "Epoch: 336/500, Loss: 2.691222789508174e-06,Train Acc: 0.9784809947013855, Val Acc: 0.9784296751022339, Val Precision: 0.9790554642677307, Val Recall: 0.9784296751022339\n",
      "Epoch: 337/500, Loss: 8.163860002241563e-06,Train Acc: 0.978486180305481, Val Acc: 0.9784350395202637, Val Precision: 0.9790605306625366, Val Recall: 0.9784350395202637\n",
      "Epoch: 338/500, Loss: 8.907989467843436e-06,Train Acc: 0.9784913659095764, Val Acc: 0.9784404039382935, Val Precision: 0.979065477848053, Val Recall: 0.9784404039382935\n",
      "Epoch: 339/500, Loss: 4.728583007818088e-06,Train Acc: 0.9784964919090271, Val Acc: 0.9784456491470337, Val Precision: 0.9790704250335693, Val Recall: 0.9784456491470337\n",
      "Epoch: 340/500, Loss: 2.6406396500533447e-06,Train Acc: 0.978501558303833, Val Acc: 0.9784508943557739, Val Precision: 0.9790753126144409, Val Recall: 0.9784508943557739\n",
      "Epoch: 341/500, Loss: 6.35774858892546e-06,Train Acc: 0.9785066843032837, Val Acc: 0.9784561395645142, Val Precision: 0.9790802001953125, Val Recall: 0.9784561395645142\n",
      "Epoch: 342/500, Loss: 1.2932305253343657e-06,Train Acc: 0.9785116910934448, Val Acc: 0.9784613251686096, Val Precision: 0.9790850877761841, Val Recall: 0.9784613251686096\n",
      "Epoch: 343/500, Loss: 4.266153609933099e-06,Train Acc: 0.978516697883606, Val Acc: 0.9784665107727051, Val Precision: 0.9790899157524109, Val Recall: 0.9784665107727051\n",
      "Epoch: 344/500, Loss: 3.5509533518052194e-06,Train Acc: 0.9785217046737671, Val Acc: 0.9784716367721558, Val Precision: 0.9790947437286377, Val Recall: 0.9784716367721558\n",
      "Epoch: 345/500, Loss: 5.021215656597633e-07,Train Acc: 0.9785266518592834, Val Acc: 0.9784767627716064, Val Precision: 0.9790995121002197, Val Recall: 0.9784767627716064\n",
      "Epoch: 346/500, Loss: 5.346286798157962e-06,Train Acc: 0.978531539440155, Val Acc: 0.9784818291664124, Val Precision: 0.9791042804718018, Val Recall: 0.9784818291664124\n",
      "Epoch: 347/500, Loss: 2.7959749786532484e-06,Train Acc: 0.9785364270210266, Val Acc: 0.9784868955612183, Val Precision: 0.979108989238739, Val Recall: 0.9784868955612183\n",
      "Epoch: 348/500, Loss: 1.4846843896521023e-06,Train Acc: 0.9785413146018982, Val Acc: 0.9784919023513794, Val Precision: 0.9791136980056763, Val Recall: 0.9784919023513794\n",
      "Epoch: 349/500, Loss: 4.266192263457924e-06,Train Acc: 0.978546142578125, Val Acc: 0.9784969091415405, Val Precision: 0.9791183471679688, Val Recall: 0.9784969091415405\n",
      "Epoch: 350/500, Loss: 5.33185038875672e-06,Train Acc: 0.978550910949707, Val Acc: 0.9785017967224121, Val Precision: 0.9791229963302612, Val Recall: 0.9785017967224121\n",
      "Epoch: 351/500, Loss: 2.629808477649931e-06,Train Acc: 0.9785557389259338, Val Acc: 0.9785068035125732, Val Precision: 0.9791276454925537, Val Recall: 0.9785068035125732\n",
      "Epoch: 352/500, Loss: 5.180113930691732e-06,Train Acc: 0.9785605072975159, Val Acc: 0.9785116910934448, Val Precision: 0.9791321754455566, Val Recall: 0.9785116910934448\n",
      "Epoch: 353/500, Loss: 2.91517926598317e-06,Train Acc: 0.9785652160644531, Val Acc: 0.9785165786743164, Val Precision: 0.9791367650032043, Val Recall: 0.9785165786743164\n",
      "Epoch: 354/500, Loss: 4.305914899305208e-06,Train Acc: 0.9785699248313904, Val Acc: 0.978521466255188, Val Precision: 0.979141354560852, Val Recall: 0.978521466255188\n",
      "Epoch: 355/500, Loss: 4.251746759109665e-06,Train Acc: 0.9785745739936829, Val Acc: 0.97852623462677, Val Precision: 0.9791458249092102, Val Recall: 0.97852623462677\n",
      "Epoch: 356/500, Loss: 3.258362994529307e-06,Train Acc: 0.9785792827606201, Val Acc: 0.978531002998352, Val Precision: 0.9791502952575684, Val Recall: 0.978531002998352\n",
      "Epoch: 357/500, Loss: 3.243902938265819e-06,Train Acc: 0.978583812713623, Val Acc: 0.9785357713699341, Val Precision: 0.9791547656059265, Val Recall: 0.9785357713699341\n",
      "Epoch: 358/500, Loss: 3.998895408585668e-06,Train Acc: 0.9785884618759155, Val Acc: 0.9785405397415161, Val Precision: 0.9791592359542847, Val Recall: 0.9785405397415161\n",
      "Epoch: 359/500, Loss: 9.825674851526855e-07,Train Acc: 0.9785929918289185, Val Acc: 0.9785452485084534, Val Precision: 0.979163646697998, Val Recall: 0.9785452485084534\n",
      "Epoch: 360/500, Loss: 1.715880671326886e-06,Train Acc: 0.9785975813865662, Val Acc: 0.9785499572753906, Val Precision: 0.9791679978370667, Val Recall: 0.9785499572753906\n",
      "Epoch: 361/500, Loss: 5.353460892365547e-06,Train Acc: 0.9786020517349243, Val Acc: 0.9785546064376831, Val Precision: 0.9791723489761353, Val Recall: 0.9785546064376831\n",
      "Epoch: 362/500, Loss: 2.810421165122534e-06,Train Acc: 0.9786065816879272, Val Acc: 0.9785592555999756, Val Precision: 0.9791767597198486, Val Recall: 0.9785592555999756\n",
      "Epoch: 363/500, Loss: 4.526290013018297e-06,Train Acc: 0.9786111116409302, Val Acc: 0.9785638451576233, Val Precision: 0.9791810512542725, Val Recall: 0.9785638451576233\n",
      "Epoch: 364/500, Loss: 1.036755861605343e-06,Train Acc: 0.9786155223846436, Val Acc: 0.978568434715271, Val Precision: 0.9791853427886963, Val Recall: 0.978568434715271\n",
      "Epoch: 365/500, Loss: 2.9368575269472785e-06,Train Acc: 0.9786199331283569, Val Acc: 0.9785729646682739, Val Precision: 0.9791895747184753, Val Recall: 0.9785729646682739\n",
      "Epoch: 366/500, Loss: 2.720123120525386e-06,Train Acc: 0.9786243438720703, Val Acc: 0.9785775542259216, Val Precision: 0.9791938066482544, Val Recall: 0.9785775542259216\n",
      "Epoch: 367/500, Loss: 2.676765689102467e-06,Train Acc: 0.9786287546157837, Val Acc: 0.9785820245742798, Val Precision: 0.9791980981826782, Val Recall: 0.9785820245742798\n",
      "Epoch: 368/500, Loss: 2.525047193557839e-06,Train Acc: 0.9786330461502075, Val Acc: 0.9785865545272827, Val Precision: 0.9792022705078125, Val Recall: 0.9785865545272827\n",
      "Epoch: 369/500, Loss: 3.1138704343902646e-06,Train Acc: 0.9786373376846313, Val Acc: 0.9785909652709961, Val Precision: 0.9792064428329468, Val Recall: 0.9785909652709961\n",
      "Epoch: 370/500, Loss: 2.2685735530103557e-06,Train Acc: 0.9786416888237, Val Acc: 0.9785954356193542, Val Precision: 0.979210615158081, Val Recall: 0.9785954356193542\n",
      "Epoch: 371/500, Loss: 2.5503331926302053e-06,Train Acc: 0.978645920753479, Val Acc: 0.9785998463630676, Val Precision: 0.9792147278785706, Val Recall: 0.9785998463630676\n",
      "Epoch: 372/500, Loss: 3.2872483188839396e-06,Train Acc: 0.9786502122879028, Val Acc: 0.9786041975021362, Val Precision: 0.9792188405990601, Val Recall: 0.9786041975021362\n",
      "Epoch: 373/500, Loss: 3.1897232020128286e-06,Train Acc: 0.9786544442176819, Val Acc: 0.9786086082458496, Val Precision: 0.9792228937149048, Val Recall: 0.9786086082458496\n",
      "Epoch: 374/500, Loss: 8.163992788468022e-07,Train Acc: 0.9786586761474609, Val Acc: 0.9786129593849182, Val Precision: 0.9792269468307495, Val Recall: 0.9786129593849182\n",
      "Epoch: 375/500, Loss: 3.709871407409082e-06,Train Acc: 0.9786628484725952, Val Acc: 0.9786173105239868, Val Precision: 0.9792309999465942, Val Recall: 0.9786173105239868\n",
      "Epoch: 376/500, Loss: 9.030974297274952e-07,Train Acc: 0.9786670207977295, Val Acc: 0.9786216020584106, Val Precision: 0.979235053062439, Val Recall: 0.9786216020584106\n",
      "Epoch: 377/500, Loss: 2.1204707536526257e-06,Train Acc: 0.9786711931228638, Val Acc: 0.9786258339881897, Val Precision: 0.9792389869689941, Val Recall: 0.9786258339881897\n",
      "Epoch: 378/500, Loss: 4.067522240802646e-06,Train Acc: 0.9786753058433533, Val Acc: 0.9786300659179688, Val Precision: 0.9792430400848389, Val Recall: 0.9786300659179688\n",
      "Epoch: 379/500, Loss: 1.8495182985134306e-06,Train Acc: 0.9786794185638428, Val Acc: 0.9786343574523926, Val Precision: 0.979246973991394, Val Recall: 0.9786343574523926\n",
      "Epoch: 380/500, Loss: 3.308934083179338e-06,Train Acc: 0.9786834716796875, Val Acc: 0.9786385297775269, Val Precision: 0.9792509078979492, Val Recall: 0.9786385297775269\n",
      "Epoch: 381/500, Loss: 2.557558445914765e-06,Train Acc: 0.9786875247955322, Val Acc: 0.9786427021026611, Val Precision: 0.9792548418045044, Val Recall: 0.9786427021026611\n",
      "Epoch: 382/500, Loss: 2.572015546320472e-06,Train Acc: 0.978691577911377, Val Acc: 0.9786468744277954, Val Precision: 0.9792587161064148, Val Recall: 0.9786468744277954\n",
      "Epoch: 383/500, Loss: 2.5503297820250737e-06,Train Acc: 0.9786955714225769, Val Acc: 0.9786510467529297, Val Precision: 0.9792625904083252, Val Recall: 0.9786510467529297\n",
      "Epoch: 384/500, Loss: 1.925395054058754e-06,Train Acc: 0.9786995649337769, Val Acc: 0.9786551594734192, Val Precision: 0.9792664051055908, Val Recall: 0.9786551594734192\n",
      "Epoch: 385/500, Loss: 6.104936574047315e-07,Train Acc: 0.9787035584449768, Val Acc: 0.9786592721939087, Val Precision: 0.9792702794075012, Val Recall: 0.9786592721939087\n",
      "Epoch: 386/500, Loss: 3.25473774864804e-06,Train Acc: 0.978707492351532, Val Acc: 0.9786633253097534, Val Precision: 0.9792740941047668, Val Recall: 0.9786633253097534\n",
      "Epoch: 387/500, Loss: 3.2113784982357174e-06,Train Acc: 0.9787114262580872, Val Acc: 0.9786673784255981, Val Precision: 0.9792779088020325, Val Recall: 0.9786673784255981\n",
      "Epoch: 388/500, Loss: 1.5424910770889255e-06,Train Acc: 0.9787153601646423, Val Acc: 0.9786714315414429, Val Precision: 0.9792816638946533, Val Recall: 0.9786714315414429\n",
      "Epoch: 389/500, Loss: 2.954928277176805e-06,Train Acc: 0.9787192344665527, Val Acc: 0.9786754250526428, Val Precision: 0.9792854189872742, Val Recall: 0.9786754250526428\n",
      "Epoch: 390/500, Loss: 2.651484010129934e-06,Train Acc: 0.9787231087684631, Val Acc: 0.9786794185638428, Val Precision: 0.979289174079895, Val Recall: 0.9786794185638428\n",
      "Epoch: 391/500, Loss: 1.650861463531328e-06,Train Acc: 0.9787269830703735, Val Acc: 0.978683352470398, Val Precision: 0.9792928695678711, Val Recall: 0.978683352470398\n",
      "Epoch: 392/500, Loss: 2.395005367361591e-06,Train Acc: 0.9787307977676392, Val Acc: 0.9786873459815979, Val Precision: 0.9792965650558472, Val Recall: 0.9786873459815979\n",
      "Epoch: 393/500, Loss: 1.8386981537332758e-06,Train Acc: 0.9787346124649048, Val Acc: 0.9786912798881531, Val Precision: 0.9793002605438232, Val Recall: 0.9786912798881531\n",
      "Epoch: 394/500, Loss: 2.4564297973483917e-07,Train Acc: 0.9787384271621704, Val Acc: 0.9786951541900635, Val Precision: 0.9793038964271545, Val Recall: 0.9786951541900635\n",
      "Epoch: 395/500, Loss: 1.838697698985925e-06,Train Acc: 0.9787421822547913, Val Acc: 0.9786990880966187, Val Precision: 0.9793075323104858, Val Recall: 0.9786990880966187\n",
      "Epoch: 396/500, Loss: 2.24329050979577e-06,Train Acc: 0.9787459373474121, Val Acc: 0.978702962398529, Val Precision: 0.9793111681938171, Val Recall: 0.978702962398529\n",
      "Epoch: 397/500, Loss: 1.817019551708654e-06,Train Acc: 0.9787496328353882, Val Acc: 0.9787068367004395, Val Precision: 0.9793148040771484, Val Recall: 0.9787068367004395\n",
      "Epoch: 398/500, Loss: 2.3299767235585023e-06,Train Acc: 0.978753387928009, Val Acc: 0.9787106513977051, Val Precision: 0.979318380355835, Val Recall: 0.9787106513977051\n",
      "Epoch: 399/500, Loss: 2.203543999712565e-06,Train Acc: 0.9787571430206299, Val Acc: 0.9787144660949707, Val Precision: 0.9793219566345215, Val Recall: 0.9787144660949707\n",
      "Epoch: 400/500, Loss: 1.7845140973804519e-06,Train Acc: 0.9787607789039612, Val Acc: 0.9787182807922363, Val Precision: 0.9793254733085632, Val Recall: 0.9787182807922363\n",
      "Epoch: 401/500, Loss: 5.3824589940632e-07,Train Acc: 0.9787644147872925, Val Acc: 0.9787220358848572, Val Precision: 0.979328989982605, Val Recall: 0.9787220358848572\n",
      "Epoch: 402/500, Loss: 2.192716237914283e-06,Train Acc: 0.9787681102752686, Val Acc: 0.978725790977478, Val Precision: 0.9793325066566467, Val Recall: 0.978725790977478\n",
      "Epoch: 403/500, Loss: 4.193957011011662e-06,Train Acc: 0.9787716865539551, Val Acc: 0.9787294864654541, Val Precision: 0.9793360233306885, Val Recall: 0.9787294864654541\n",
      "Epoch: 404/500, Loss: 1.3438067298920942e-06,Train Acc: 0.9787753224372864, Val Acc: 0.978733241558075, Val Precision: 0.9793394804000854, Val Recall: 0.978733241558075\n",
      "Epoch: 405/500, Loss: 1.6616975244687637e-06,Train Acc: 0.9787788987159729, Val Acc: 0.978736937046051, Val Precision: 0.9793429374694824, Val Recall: 0.978736937046051\n",
      "Epoch: 406/500, Loss: 1.0837125046236906e-06,Train Acc: 0.9787825345993042, Val Acc: 0.9787406325340271, Val Precision: 0.9793463945388794, Val Recall: 0.9787406325340271\n",
      "Epoch: 407/500, Loss: 1.8206369531981181e-06,Train Acc: 0.978786051273346, Val Acc: 0.9787442684173584, Val Precision: 0.9793498516082764, Val Recall: 0.9787442684173584\n",
      "Epoch: 408/500, Loss: 3.35952506702597e-07,Train Acc: 0.9787895679473877, Val Acc: 0.9787479639053345, Val Precision: 0.9793532490730286, Val Recall: 0.9787479639053345\n",
      "Epoch: 409/500, Loss: 1.8531549130784697e-06,Train Acc: 0.9787931442260742, Val Acc: 0.978751540184021, Val Precision: 0.9793566465377808, Val Recall: 0.978751540184021\n",
      "Epoch: 410/500, Loss: 2.109632532665273e-06,Train Acc: 0.9787966012954712, Val Acc: 0.9787551760673523, Val Precision: 0.979360044002533, Val Recall: 0.9787551760673523\n",
      "Epoch: 411/500, Loss: 9.825700999499531e-07,Train Acc: 0.9788000583648682, Val Acc: 0.9787588119506836, Val Precision: 0.9793633818626404, Val Recall: 0.9787588119506836\n",
      "Epoch: 412/500, Loss: 9.645083309806068e-07,Train Acc: 0.9788035154342651, Val Acc: 0.9787623286247253, Val Precision: 0.9793667793273926, Val Recall: 0.9787623286247253\n",
      "Epoch: 413/500, Loss: 1.0150827165489318e-06,Train Acc: 0.9788069725036621, Val Acc: 0.9787659049034119, Val Precision: 0.9793701171875, Val Recall: 0.9787659049034119\n",
      "Epoch: 414/500, Loss: 1.647249291636399e-06,Train Acc: 0.9788104295730591, Val Acc: 0.9787694215774536, Val Precision: 0.9793733954429626, Val Recall: 0.9787694215774536\n",
      "Epoch: 415/500, Loss: 1.3112968417772208e-06,Train Acc: 0.978813886642456, Val Acc: 0.9787729978561401, Val Precision: 0.9793766736984253, Val Recall: 0.9787729978561401\n",
      "Epoch: 416/500, Loss: 7.405396900139749e-07,Train Acc: 0.9788172841072083, Val Acc: 0.9787764549255371, Val Precision: 0.9793800115585327, Val Recall: 0.9787764549255371\n",
      "Epoch: 417/500, Loss: 8.669736644151271e-07,Train Acc: 0.9788206815719604, Val Acc: 0.9787799715995789, Val Precision: 0.9793832302093506, Val Recall: 0.9787799715995789\n",
      "Epoch: 418/500, Loss: 7.802719892424648e-07,Train Acc: 0.9788240194320679, Val Acc: 0.9787834882736206, Val Precision: 0.9793864488601685, Val Recall: 0.9787834882736206\n",
      "Epoch: 419/500, Loss: 7.730523634563724e-07,Train Acc: 0.9788273572921753, Val Acc: 0.9787869453430176, Val Precision: 0.9793897271156311, Val Recall: 0.9787869453430176\n",
      "Epoch: 420/500, Loss: 1.3076845561954542e-06,Train Acc: 0.9788306951522827, Val Acc: 0.9787903428077698, Val Precision: 0.979392945766449, Val Recall: 0.9787903428077698\n",
      "Epoch: 421/500, Loss: 1.1595780051720794e-06,Train Acc: 0.9788340330123901, Val Acc: 0.978793740272522, Val Precision: 0.9793961048126221, Val Recall: 0.978793740272522\n",
      "Epoch: 422/500, Loss: 1.502754116700089e-06,Train Acc: 0.9788373708724976, Val Acc: 0.978797197341919, Val Precision: 0.9793993234634399, Val Recall: 0.978797197341919\n",
      "Epoch: 423/500, Loss: 1.4232822422854952e-06,Train Acc: 0.9788406491279602, Val Acc: 0.9788005948066711, Val Precision: 0.9794025421142578, Val Recall: 0.9788005948066711\n",
      "Epoch: 424/500, Loss: 1.0042455187431187e-06,Train Acc: 0.9788439273834229, Val Acc: 0.9788039922714233, Val Precision: 0.9794056415557861, Val Recall: 0.9788039922714233\n",
      "Epoch: 425/500, Loss: 1.8676038280318608e-06,Train Acc: 0.9788471460342407, Val Acc: 0.9788073301315308, Val Precision: 0.979408860206604, Val Recall: 0.9788073301315308\n",
      "Epoch: 426/500, Loss: 1.347422994513181e-06,Train Acc: 0.9788504242897034, Val Acc: 0.9788106679916382, Val Precision: 0.9794119596481323, Val Recall: 0.9788106679916382\n",
      "Epoch: 427/500, Loss: 1.2860091374022886e-06,Train Acc: 0.9788536429405212, Val Acc: 0.9788140058517456, Val Precision: 0.9794150590896606, Val Recall: 0.9788140058517456\n",
      "Epoch: 428/500, Loss: 2.1746511720266426e-06,Train Acc: 0.9788568615913391, Val Acc: 0.9788172841072083, Val Precision: 0.979418158531189, Val Recall: 0.9788172841072083\n",
      "Epoch: 429/500, Loss: 1.1415137350923032e-06,Train Acc: 0.9788590669631958, Val Acc: 0.9788196086883545, Val Precision: 0.9794197082519531, Val Recall: 0.9788196086883545\n",
      "Epoch: 430/500, Loss: 1.0692667729017558e-06,Train Acc: 0.9788622856140137, Val Acc: 0.9788229465484619, Val Precision: 0.9794228076934814, Val Recall: 0.9788229465484619\n",
      "Epoch: 431/500, Loss: 1.7592300309843267e-06,Train Acc: 0.9788655042648315, Val Acc: 0.9788261651992798, Val Precision: 0.979425847530365, Val Recall: 0.9788261651992798\n",
      "Epoch: 432/500, Loss: 2.6731754587672185e-07,Train Acc: 0.9788686037063599, Val Acc: 0.9788294434547424, Val Precision: 0.9794288873672485, Val Recall: 0.9788294434547424\n",
      "Epoch: 433/500, Loss: 5.707582886316231e-07,Train Acc: 0.978871762752533, Val Acc: 0.9788327217102051, Val Precision: 0.9794318675994873, Val Recall: 0.9788327217102051\n",
      "Epoch: 434/500, Loss: 5.924327410866681e-07,Train Acc: 0.978874921798706, Val Acc: 0.978835940361023, Val Precision: 0.9794349670410156, Val Recall: 0.978835940361023\n",
      "Epoch: 435/500, Loss: 1.4521821185553563e-06,Train Acc: 0.9788780212402344, Val Acc: 0.9788391590118408, Val Precision: 0.9794379472732544, Val Recall: 0.9788391590118408\n",
      "Epoch: 436/500, Loss: 1.7014323248076835e-06,Train Acc: 0.9788801670074463, Val Acc: 0.9788413643836975, Val Precision: 0.979439377784729, Val Recall: 0.9788413643836975\n",
      "Epoch: 437/500, Loss: 8.525250905222492e-07,Train Acc: 0.9788832664489746, Val Acc: 0.9788445234298706, Val Precision: 0.9794423580169678, Val Recall: 0.9788445234298706\n",
      "Epoch: 438/500, Loss: 8.34462866805552e-07,Train Acc: 0.9788863658905029, Val Acc: 0.9788477420806885, Val Precision: 0.9794453382492065, Val Recall: 0.9788477420806885\n",
      "Epoch: 439/500, Loss: 4.1903805936271965e-07,Train Acc: 0.9788894057273865, Val Acc: 0.9788509011268616, Val Precision: 0.9794483184814453, Val Recall: 0.9788509011268616\n",
      "Epoch: 440/500, Loss: 2.456429228914203e-07,Train Acc: 0.97889244556427, Val Acc: 0.9788540601730347, Val Precision: 0.9794512391090393, Val Recall: 0.9788540601730347\n",
      "Epoch: 441/500, Loss: 7.911145303296507e-07,Train Acc: 0.9788954854011536, Val Acc: 0.978857159614563, Val Precision: 0.9794541597366333, Val Recall: 0.978857159614563\n",
      "Epoch: 442/500, Loss: 1.0331448265787913e-06,Train Acc: 0.9788985252380371, Val Acc: 0.9788602590560913, Val Precision: 0.9794570207595825, Val Recall: 0.9788602590560913\n",
      "Epoch: 443/500, Loss: 7.58603164285887e-07,Train Acc: 0.9789015054702759, Val Acc: 0.9788633584976196, Val Precision: 0.9794600009918213, Val Recall: 0.9788633584976196\n",
      "Epoch: 444/500, Loss: 1.7664591496213689e-06,Train Acc: 0.9789044857025146, Val Acc: 0.978866457939148, Val Precision: 0.9794628620147705, Val Recall: 0.978866457939148\n",
      "Epoch: 445/500, Loss: 9.283859299102915e-07,Train Acc: 0.978906512260437, Val Acc: 0.9788686037063599, Val Precision: 0.9794642329216003, Val Recall: 0.9788686037063599\n",
      "Epoch: 446/500, Loss: 1.3799344742437825e-06,Train Acc: 0.9789094924926758, Val Acc: 0.9788716435432434, Val Precision: 0.9794670939445496, Val Recall: 0.9788716435432434\n",
      "Epoch: 447/500, Loss: 7.586022547911853e-07,Train Acc: 0.9789124727249146, Val Acc: 0.978874683380127, Val Precision: 0.9794699549674988, Val Recall: 0.978874683380127\n",
      "Epoch: 448/500, Loss: 3.756892112960486e-07,Train Acc: 0.9789153933525085, Val Acc: 0.9788777232170105, Val Precision: 0.9794727563858032, Val Recall: 0.9788777232170105\n",
      "Epoch: 449/500, Loss: 1.1487411484267795e-06,Train Acc: 0.9789183139801025, Val Acc: 0.978880763053894, Val Precision: 0.9794756174087524, Val Recall: 0.978880763053894\n",
      "Epoch: 450/500, Loss: 5.093474442219303e-07,Train Acc: 0.9789212346076965, Val Acc: 0.9788837432861328, Val Precision: 0.9794784188270569, Val Recall: 0.9788837432861328\n",
      "Epoch: 451/500, Loss: 6.719058092130581e-07,Train Acc: 0.9789241552352905, Val Acc: 0.9788867235183716, Val Precision: 0.9794812202453613, Val Recall: 0.9788867235183716\n",
      "Epoch: 452/500, Loss: 9.067103974302881e-07,Train Acc: 0.9789270162582397, Val Acc: 0.9788897037506104, Val Precision: 0.9794840216636658, Val Recall: 0.9788897037506104\n",
      "Epoch: 453/500, Loss: 4.0820083313519717e-07,Train Acc: 0.978929877281189, Val Acc: 0.9788926839828491, Val Precision: 0.9794868230819702, Val Recall: 0.9788926839828491\n",
      "Epoch: 454/500, Loss: 5.165722996025579e-07,Train Acc: 0.9789319038391113, Val Acc: 0.9788947105407715, Val Precision: 0.9794880747795105, Val Recall: 0.9788947105407715\n",
      "Epoch: 455/500, Loss: 7.008046623013797e-07,Train Acc: 0.9789347052574158, Val Acc: 0.9788976311683655, Val Precision: 0.9794908761978149, Val Recall: 0.9788976311683655\n",
      "Epoch: 456/500, Loss: 2.3480592403757328e-07,Train Acc: 0.978937566280365, Val Acc: 0.9789005517959595, Val Precision: 0.9794936180114746, Val Recall: 0.9789005517959595\n",
      "Epoch: 457/500, Loss: 3.431777599871566e-07,Train Acc: 0.9789403676986694, Val Acc: 0.9789034724235535, Val Precision: 0.9794963598251343, Val Recall: 0.9789034724235535\n",
      "Epoch: 458/500, Loss: 6.285563358687796e-07,Train Acc: 0.9789432287216187, Val Acc: 0.9789063930511475, Val Precision: 0.9794989824295044, Val Recall: 0.9789063930511475\n",
      "Epoch: 459/500, Loss: 8.019503070499923e-07,Train Acc: 0.9789459705352783, Val Acc: 0.9789092540740967, Val Precision: 0.9795017242431641, Val Recall: 0.9789092540740967\n",
      "Epoch: 460/500, Loss: 5.093478989692812e-07,Train Acc: 0.9789478778839111, Val Acc: 0.978911280632019, Val Precision: 0.9795029759407043, Val Recall: 0.978911280632019\n",
      "Epoch: 461/500, Loss: 8.886487989911984e-07,Train Acc: 0.9789506793022156, Val Acc: 0.9789141416549683, Val Precision: 0.9795056581497192, Val Recall: 0.9789141416549683\n",
      "Epoch: 462/500, Loss: 1.513590518698038e-06,Train Acc: 0.97895348072052, Val Acc: 0.9789170026779175, Val Precision: 0.9795083999633789, Val Recall: 0.9789170026779175\n",
      "Epoch: 463/500, Loss: 7.008048896750552e-07,Train Acc: 0.9789562225341797, Val Acc: 0.9789198040962219, Val Precision: 0.979511022567749, Val Recall: 0.9789198040962219\n",
      "Epoch: 464/500, Loss: 8.019506481105054e-07,Train Acc: 0.9789589643478394, Val Acc: 0.9789226055145264, Val Precision: 0.9795136451721191, Val Recall: 0.9789226055145264\n",
      "Epoch: 465/500, Loss: 1.8423233427711239e-07,Train Acc: 0.978961706161499, Val Acc: 0.9789254665374756, Val Precision: 0.9795162677764893, Val Recall: 0.9789254665374756\n",
      "Epoch: 466/500, Loss: 4.948981313646073e-07,Train Acc: 0.9789643883705139, Val Acc: 0.9789282083511353, Val Precision: 0.9795188903808594, Val Recall: 0.9789282083511353\n",
      "Epoch: 467/500, Loss: 9.500594728706346e-07,Train Acc: 0.9789670705795288, Val Acc: 0.9789310693740845, Val Precision: 0.9795215129852295, Val Recall: 0.9789310693740845\n",
      "Epoch: 468/500, Loss: 5.382472636483726e-07,Train Acc: 0.9789698123931885, Val Acc: 0.9789338111877441, Val Precision: 0.9795241355895996, Val Recall: 0.9789338111877441\n",
      "Epoch: 469/500, Loss: 6.177199338708306e-07,Train Acc: 0.9789724946022034, Val Acc: 0.9789366126060486, Val Precision: 0.9795267581939697, Val Recall: 0.9789366126060486\n",
      "Epoch: 470/500, Loss: 8.99485769423336e-07,Train Acc: 0.9789743423461914, Val Acc: 0.9789384603500366, Val Precision: 0.9795279502868652, Val Recall: 0.9789384603500366\n",
      "Epoch: 471/500, Loss: 5.526968038793711e-07,Train Acc: 0.9789769649505615, Val Acc: 0.9789412021636963, Val Precision: 0.9795305132865906, Val Recall: 0.9789412021636963\n",
      "Epoch: 472/500, Loss: 1.7700733678793767e-07,Train Acc: 0.9789787530899048, Val Acc: 0.9789431095123291, Val Precision: 0.9795316457748413, Val Recall: 0.9789431095123291\n",
      "Epoch: 473/500, Loss: 5.310224651111639e-07,Train Acc: 0.9789813756942749, Val Acc: 0.978945791721344, Val Precision: 0.9795342087745667, Val Recall: 0.978945791721344\n",
      "Epoch: 474/500, Loss: 3.9013912100926973e-07,Train Acc: 0.978983998298645, Val Acc: 0.9789485335350037, Val Precision: 0.979536771774292, Val Recall: 0.9789485335350037\n",
      "Epoch: 475/500, Loss: 5.093482400297944e-07,Train Acc: 0.9789857864379883, Val Acc: 0.9789503812789917, Val Precision: 0.9795379042625427, Val Recall: 0.9789503812789917\n",
      "Epoch: 476/500, Loss: 1.3943819112682831e-06,Train Acc: 0.9789884090423584, Val Acc: 0.9789530038833618, Val Precision: 0.9795404076576233, Val Recall: 0.9789530038833618\n",
      "Epoch: 477/500, Loss: 3.612401044961189e-08,Train Acc: 0.9789910316467285, Val Acc: 0.9789557456970215, Val Precision: 0.9795429110527039, Val Recall: 0.9789557456970215\n",
      "Epoch: 478/500, Loss: 2.6009266207438486e-07,Train Acc: 0.9789935946464539, Val Acc: 0.9789583683013916, Val Precision: 0.9795454740524292, Val Recall: 0.9789583683013916\n",
      "Epoch: 479/500, Loss: 2.6731754587672185e-07,Train Acc: 0.9789953231811523, Val Acc: 0.9789602160453796, Val Precision: 0.9795465469360352, Val Recall: 0.9789602160453796\n",
      "Epoch: 480/500, Loss: 5.418593786998827e-07,Train Acc: 0.9789961576461792, Val Acc: 0.9789611101150513, Val Precision: 0.979546308517456, Val Recall: 0.9789611101150513\n",
      "Epoch: 481/500, Loss: 5.093482400297944e-07,Train Acc: 0.9789978861808777, Val Acc: 0.9789628982543945, Val Precision: 0.979547381401062, Val Recall: 0.9789628982543945\n",
      "Epoch: 482/500, Loss: 2.2396874044261494e-07,Train Acc: 0.9789996147155762, Val Acc: 0.9789646863937378, Val Precision: 0.979548454284668, Val Recall: 0.9789646863937378\n",
      "Epoch: 483/500, Loss: 4.04588774927106e-07,Train Acc: 0.9790021181106567, Val Acc: 0.9789673089981079, Val Precision: 0.9795509576797485, Val Recall: 0.9789673089981079\n",
      "Epoch: 484/500, Loss: 2.4564315026509576e-07,Train Acc: 0.9790038466453552, Val Acc: 0.9789690971374512, Val Precision: 0.9795520305633545, Val Recall: 0.9789690971374512\n",
      "Epoch: 485/500, Loss: 3.829142940503516e-07,Train Acc: 0.9790055155754089, Val Acc: 0.9789708852767944, Val Precision: 0.9795531034469604, Val Recall: 0.9789708852767944\n",
      "Epoch: 486/500, Loss: 6.393939315785246e-07,Train Acc: 0.9790080189704895, Val Acc: 0.9789734482765198, Val Precision: 0.9795554876327515, Val Recall: 0.9789734482765198\n",
      "Epoch: 487/500, Loss: 2.781546584174066e-07,Train Acc: 0.9790096879005432, Val Acc: 0.9789751768112183, Val Precision: 0.9795565605163574, Val Recall: 0.9789751768112183\n",
      "Epoch: 488/500, Loss: 7.224803511007849e-08,Train Acc: 0.9790114164352417, Val Acc: 0.9789769053459167, Val Precision: 0.9795576333999634, Val Recall: 0.9789769053459167\n",
      "Epoch: 489/500, Loss: 8.669760376278646e-08,Train Acc: 0.9790129661560059, Val Acc: 0.9789786338806152, Val Precision: 0.9795587062835693, Val Recall: 0.9789786338806152\n",
      "Epoch: 490/500, Loss: 2.9260431233524287e-07,Train Acc: 0.9790146350860596, Val Acc: 0.9789803624153137, Val Precision: 0.9795597791671753, Val Recall: 0.9789803624153137\n",
      "Epoch: 491/500, Loss: 3.504021606204333e-07,Train Acc: 0.9790163040161133, Val Acc: 0.9789820909500122, Val Precision: 0.9795607924461365, Val Recall: 0.9789820909500122\n",
      "Epoch: 492/500, Loss: 5.201853241487697e-07,Train Acc: 0.979017972946167, Val Acc: 0.9789837598800659, Val Precision: 0.9795618057250977, Val Recall: 0.9789837598800659\n",
      "Epoch: 493/500, Loss: 6.35780850188894e-07,Train Acc: 0.9790204167366028, Val Acc: 0.9789862632751465, Val Precision: 0.9795642495155334, Val Recall: 0.9789862632751465\n",
      "Epoch: 494/500, Loss: 5.418587534222752e-07,Train Acc: 0.9790228605270386, Val Acc: 0.9789888858795166, Val Precision: 0.9795665740966797, Val Recall: 0.9789888858795166\n",
      "Epoch: 495/500, Loss: 2.9621656949530006e-07,Train Acc: 0.9790244698524475, Val Acc: 0.9789905548095703, Val Precision: 0.9795676469802856, Val Recall: 0.9789905548095703\n",
      "Epoch: 496/500, Loss: 3.7207718150966684e-07,Train Acc: 0.9790260791778564, Val Acc: 0.9789921641349792, Val Precision: 0.9795686602592468, Val Recall: 0.9789921641349792\n",
      "Epoch: 497/500, Loss: 2.5648031964919937e-07,Train Acc: 0.9790276288986206, Val Acc: 0.9789938926696777, Val Precision: 0.979569673538208, Val Recall: 0.9789938926696777\n",
      "Epoch: 498/500, Loss: 5.093482400297944e-07,Train Acc: 0.9790292382240295, Val Acc: 0.9789955019950867, Val Precision: 0.979570746421814, Val Recall: 0.9789955019950867\n",
      "Epoch: 499/500, Loss: 5.526965765056957e-07,Train Acc: 0.9790308475494385, Val Acc: 0.9789971709251404, Val Precision: 0.9795717000961304, Val Recall: 0.9789971709251404\n",
      "Epoch: 500/500, Loss: 2.8537951379803417e-07,Train Acc: 0.9790323972702026, Val Acc: 0.9789988398551941, Val Precision: 0.9795727133750916, Val Recall: 0.9789988398551941\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model_1.train_model(training_loader_original, validation_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T14:11:17.149358Z",
     "start_time": "2024-05-11T13:31:35.595771Z"
    }
   },
   "id": "7daafd896f0e0ee1",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9790127277374268, Precision: 0.9795866012573242, Recall: 0.9790127277374268\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec = model_1.eval_val(testing_loader)\n",
    "print(f'Accuracy: {acc}, Precision: {prec}, Recall: {rec}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T14:11:17.460419Z",
     "start_time": "2024-05-11T14:11:17.150404Z"
    }
   },
   "id": "ead396b7b7d770b7",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model_1.train_model(training_loader_modified, validation_loader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4a564d2b39ce3dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# acc, prec, rec = model_1.eval_val(testing_loader)\n",
    "# print(f'Accuracy: {acc}, Precision: {prec}, Recall: {rec}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbbeb9564dd5c30e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
